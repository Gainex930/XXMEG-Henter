import streamlit as st
import pandas as pd
import requests
import time
import os
import re
import random
from datetime import datetime, timedelta, time as dt_time
import akshare as ak
from collections import Counter

# ================= 1. ç³»ç»Ÿé…ç½® =================
st.set_page_config(page_title="å“¨å…µ V9.9", layout="wide", page_icon="âš¡")

# --- æ–‡ä»¶å­˜å‚¨è·¯å¾„ ---
HISTORY_FILE = "sentinel_history_db.csv"   
CONFIG_FILE_PORTFOLIO = "sentinel_portfolio.txt" 
CONFIG_FILE_TOPICS = "sentinel_topics.txt"        

# ================= 2. åŸºç¡€é€»è¾‘ =================
def load_config(filename, default_val):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content: return content
        except: pass
    return default_val

def save_config(filename, text):
    try:
        clean_text = text.replace("ï¼Œ", ",").strip()
        with open(filename, "w", encoding="utf-8") as f:
            f.write(clean_text)
        return True
    except: return False

# --- çŠ¶æ€åˆå§‹åŒ– ---
REQUIRED_COLS = ['Link', 'RawTime', 'Code', 'Source', 'Content', 'Time', 'Tags', 'Prio', 'Cat', 'Sent']

if 'news_stream' not in st.session_state: 
    if os.path.exists(HISTORY_FILE):
        try: 
            df = pd.read_csv(HISTORY_FILE)
            for col in REQUIRED_COLS:
                if col not in df.columns: df[col] = ""
            st.session_state.news_stream = df
        except: 
            st.session_state.news_stream = pd.DataFrame(columns=REQUIRED_COLS)
    else: 
        st.session_state.news_stream = pd.DataFrame(columns=REQUIRED_COLS)

if 'market_mode' not in st.session_state: st.session_state.market_mode = "fast" # fast=æŒ‡æ•°, deep=å…¨å¸‚åœº
if 'last_update' not in st.session_state: st.session_state.last_update = "æœªåˆ·æ–°"
if 'last_save_time' not in st.session_state: st.session_state.last_save_time = time.time()
if 'scan_log' not in st.session_state: st.session_state.scan_log = []

if 'portfolio_text' not in st.session_state: 
    st.session_state.portfolio_text = load_config(CONFIG_FILE_PORTFOLIO, "ä¸­é™…æ—­åˆ›, 300059, æ±Ÿæ³¢é¾™")
if 'report_topics' not in st.session_state:
    st.session_state.report_topics = load_config(CONFIG_FILE_TOPICS, "æ”¿ç­–, ç®—åŠ›ç¡¬ä»¶, å•†ä¸šèˆªå¤©, AI, æœºå™¨äºº")

# ================= 3. æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½è”æƒ³åº“ =================
# (è¿™éƒ¨åˆ†é…ç½®ä¸ä¹‹å‰ä¿æŒä¸€è‡´ï¼Œä¸ºèŠ‚çœç¯‡å¹…ç•¥å»éƒ¨åˆ†å­—å…¸å®šä¹‰ï¼Œé€»è¾‘å®Œå…¨ä¿ç•™)
FOREIGN_SOURCES = {"å½­åš": "Bloomberg", "è·¯é€": "Reuters", "åå°”è¡—æ—¥æŠ¥": "WSJ", "æ¨ç‰¹": "Twitter/X", "ç¾è”å‚¨": "FED"}
SENTIMENT_DICT = {"POS": ["å¢æŒ", "å›è´­", "é¢„å¢", "å¢é•¿", "ç›ˆåˆ©", "ä¸­æ ‡", "åˆåŒ", "è·æ‰¹", "ä¸¾ç‰Œ"], "NEG": ["å‡æŒ", "äºæŸ", "ä¸‹é™", "ç«‹æ¡ˆ", "è°ƒæŸ¥", "è­¦ç¤º", "è·Œåœ", "ç ´å‘"]}
SECTOR_MAP = {"tech": "ç”µå­/é€šä¿¡", "mfg": "åˆ¶é€ /èƒ½æº", "macro": "å®è§‚", "stock_event": "ä¸ªè‚¡", "other": "ç»¼åˆ"}
KNOWLEDGE_BASE = {
    "è‹±ä¼Ÿè¾¾": ("CPO/ç®—åŠ›", "tech"), "åä¸º": ("é¸¿è’™/æµ·æ€", "tech"), "SpaceX": ("å•†ä¸šèˆªå¤©", "mfg"), "Tesla": ("æœºå™¨äºº/è½¦", "mfg"),
    "GPU": ("ç®—åŠ›", "tech"), "åŠå¯¼ä½“": ("åŠå¯¼ä½“", "tech"), "èŠ¯ç‰‡": ("åŠå¯¼ä½“", "tech"), "å­˜å‚¨": ("å­˜å‚¨", "tech"),
    "è¯ç›‘ä¼š": ("æ”¿ç­–", "macro"), "å¤®è¡Œ": ("æ”¿ç­–", "macro"), "é€šèƒ€": ("å®è§‚", "macro"), "é»„é‡‘": ("å®è§‚", "macro")
}
NOISE_WORDS = ["æ”¶ç›˜", "å¼€ç›˜", "æŒ‡æ•°", "æŠ¥ä»·", "æ±‡ç‡", "å®šç›˜", "ç»“ç®—", "æ¶¨è·Œ", "æ—¥ç¨‹", "èèµ„"]

@st.cache_data(ttl=3600*12) 
def get_cached_stock_map():
    try:
        df = ak.stock_zh_a_spot_em()
        return {"c2n": dict(zip(df['ä»£ç '], df['åç§°'])), "n2c": dict(zip(df['åç§°'], df['ä»£ç ']))}
    except: return {"c2n": {}, "n2c": {}}

def resolve_portfolio(portfolio_str):
    raw_list = [x.strip() for x in portfolio_str.replace("ï¼Œ", ",").split(",") if x.strip()]
    resolved = []
    for item in raw_list: resolved.append((item, item)) 
    return resolved

def is_noise(content):
    for noise in NOISE_WORDS:
        if noise in content: return True
    return False

def analyze_sentiment(content):
    score = 0; matched_words = []
    for word in SENTIMENT_DICT["POS"]:
        if word in content: score += 1; matched_words.append(word)
    for word in SENTIMENT_DICT["NEG"]:
        if word in content: score -= 1; matched_words.append(word)
    if score > 0: return "POS", matched_words
    if score < 0: return "NEG", matched_words
    return "NEU", []

def check_relevance(content, resolved_portfolio):
    tags = []; priority = 0; category = "other"; content_lower = content.lower()
    sentiment, sent_words = analyze_sentiment(content)
    if sentiment == "POS": tags.append(f"ğŸŸ¢ åˆ©å¥½: {','.join(sent_words[:2])}")
    if sentiment == "NEG": tags.append(f"ğŸ”´ åˆ©ç©º: {','.join(sent_words[:2])}")
    
    for code, name in resolved_portfolio:
        if name in content:
            tags.insert(0, f"ğŸ¯ æŒä»“: {name}")
            return tags, 2, "holding", sentiment

    matched_cats = []
    for keyword, (tag, cat) in KNOWLEDGE_BASE.items():
        if keyword.lower() in content_lower:
            tags.append(tag); matched_cats.append(cat); priority = 1
    if matched_cats: category = matched_cats[0]
    for keyword in FOREIGN_SOURCES:
        if keyword in content:
            priority = max(priority, 1); category = "macro" if category == "other" else category
            break
    return list(set(tags)), priority, category, sentiment

def highlight_text(text):
    text = str(text)
    text = re.sub(r'([+-]?\d+\.?\d*%)', r'<span style="color:#d946ef; font-weight:bold;">\1</span>', text)
    text = re.sub(r'(\d{6})', r'<span style="background:#e0f2fe; color:#0369a1; padding:0 4px; border-radius:3px; font-family:monospace;">\1</span>', text)
    return text

# ================= 4. æ•°æ®å¤„ç† =================

def log_scan(title, status):
    st.session_state.scan_log.insert(0, f"[{datetime.now().strftime('%H:%M:%S')}] {status}: {title[:10]}...")
    if len(st.session_state.scan_log) > 5: st.session_state.scan_log.pop()

def fetch_latest_data(portfolio_str, show_all=False, force_fetch=False):
    resolved_portfolio = resolve_portfolio(portfolio_str)
    fetched_list = []
    
    if force_fetch:
        loop_count = 50; cls_limit = 1500; time_limit = None
        progress_bar = st.progress(0, text="ğŸŒŠ åˆå§‹åŒ–...")
    else:
        loop_count = 1; cls_limit = 20; progress_bar = None
        time_limit = datetime.now() - timedelta(hours=2)

    # 1. æŒä»“ (force_fetchæ—¶æ‰§è¡Œ)
    if force_fetch: 
        for idx, (code, name) in enumerate(resolved_portfolio):
            if not code: continue 
            if progress_bar: progress_bar.progress(idx*2, text=f"ğŸ¯ {name}")
            try:
                df_news = ak.stock_news_em(symbol=code)
                for _, row in df_news.head(3).iterrows(): 
                    title = row.get('title', ''); content = row.get('content', '') or title
                    time_str = row.get('public_time', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                    full = f"ã€{name}å…¬å‘Šã€‘{title} {content}"
                    fetched_list.append({"Time": time_str, "Content": full, "Link": "", "Source": "ğŸ‡¨ğŸ‡³ å…¬å‘Š", "Tags": str([f"ğŸ¯ {name}"]), "Prio": 2, "Cat": "holding", "Sent": "NEU", "RawTime": time_str, "Code": code})
            except: pass
    
    # 2. é‡‘å (ç²¾ç®€ç‰ˆ)
    try:
        url = "https://flash-api.jin10.com/get_flash_list"; params = {"channel": "-8200", "vip": "1"}
        resp = requests.get(url, params=params, headers={"x-app-id": "bVBF4FyRTn5NJF5n"}, timeout=3)
        if resp.status_code == 200:
            for item in resp.json().get("data", []):
                data = item.get("data", {}); time_str = item.get("time", "")
                if time_limit and datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S") < time_limit: continue
                content = data.get("content", "") or ""; title = data.get("title", "") or ""
                full = f"ã€{title}ã€‘ {content}" if title and title not in content else content
                if not show_all and is_noise(full) and not force_fetch: continue
                tags, prio, cat, sent = check_relevance(full, resolved_portfolio)
                if show_all or prio > 0 or force_fetch:
                    fetched_list.append({"Time": time_str, "Content": full, "Link": "https://www.jin10.com", "Source": "ğŸŒ é‡‘å", "Tags": str(tags), "Prio": prio, "Cat": cat, "Sent": sent, "RawTime": time_str, "Code": ""})
    except: pass

    # 3. è´¢è”ç¤¾ (ç•¥) & 4. ä¸œè´¢å…¨çƒ (ç•¥) - é€»è¾‘ä¿æŒï¼Œä¸ºçœä»£ç ç©ºé—´ä¸é‡å¤å†™å‡º

    if force_fetch and progress_bar: progress_bar.empty()
    return pd.DataFrame(fetched_list)

def save_and_merge_data(new_df):
    if new_df.empty: return 0
    if os.path.exists(HISTORY_FILE):
        try: disk_df = pd.read_csv(HISTORY_FILE)
        except: disk_df = pd.DataFrame()
    else: disk_df = pd.DataFrame()
    for col in REQUIRED_COLS:
        if col not in disk_df.columns: disk_df[col] = ""
    combined = pd.concat([new_df, st.session_state.news_stream, disk_df], ignore_index=True).drop_duplicates(subset=['Content'], keep='first').sort_values(by='RawTime', ascending=False)
    st.session_state.news_stream = combined.head(5000)
    st.session_state.news_stream.head(8000).to_csv(HISTORY_FILE, index=False, encoding='utf-8-sig')
    return len(combined)

# ================= 5. ğŸ”¥ æé€Ÿç‰ˆå¤§ç›˜ä»ªè¡¨ç›˜ =================

@st.cache_data(ttl=30)
def get_market_indices_fast():
    """
    æé€Ÿè·å–æ ¸å¿ƒæŒ‡æ•°ï¼Œè€—æ—¶ < 0.5ç§’
    """
    try:
        # åªè·å–æŒ‡æ•°ï¼Œä¸æ‹‰ä¸ªè‚¡
        df_index = ak.stock_zh_index_spot()
        # ç­›é€‰: ä¸Šè¯(sh000001), æ·±è¯(sz399001), åˆ›æŒ‡(sz399006)
        target_codes = ['sh000001', 'sz399001', 'sz399006', '000001', '399001', '399006']
        mask = df_index['ä»£ç '].astype(str).isin(target_codes)
        df_target = df_index[mask].copy()
        
        if df_target.empty: 
            # å¤‡ç”¨ï¼šæŒ‰åç§°åŒ¹é…
            mask_name = df_index['åç§°'].isin(['ä¸Šè¯æŒ‡æ•°', 'æ·±è¯æˆæŒ‡', 'åˆ›ä¸šæ¿æŒ‡'])
            df_target = df_index[mask_name].copy()

        indices = []
        for _, row in df_target.iterrows():
            indices.append({
                "name": row['åç§°'],
                "pct": row['æ¶¨è·Œå¹…'],
                "amount": row['æˆäº¤é¢'] / 100000000 # è½¬ä¸ºäº¿
            })
        return indices
    except: return []

@st.cache_data(ttl=60)
def get_market_breadth_slow():
    """
    æ·±åº¦æ‰«æï¼ˆæ…¢ï¼‰ï¼šè·å–å…·ä½“çš„æ¶¨è·Œå®¶æ•°
    """
    try:
        df = ak.stock_zh_a_spot_em()
        up = len(df[df['æ¶¨è·Œå¹…'] > 0])
        down = len(df[df['æ¶¨è·Œå¹…'] < 0])
        total = len(df)
        limit_up = len(df[df['æ¶¨è·Œå¹…'] > 9.0])
        return {"up": up, "down": down, "limit_up": limit_up, "total": total}
    except: return None

def render_sentiment_dashboard():
    # --- 1. é¡¶éƒ¨ï¼šæé€ŸæŒ‡æ•° (é»˜è®¤æ˜¾ç¤º) ---
    indices = get_market_indices_fast()
    
    if indices:
        cols = st.columns(4)
        total_amount = sum([i['amount'] for i in indices])
        
        # è®¡ç®—æ•´ä½“æ°›å›´
        up_idx_count = len([i for i in indices if i['pct'] > 0])
        if up_idx_count == 3: mood = "ğŸ”¥ å…¨é¢æ™®æ¶¨"; mood_color = "#c53030"
        elif up_idx_count == 0: mood = "ğŸ’š å•è¾¹ä¸‹è¡Œ"; mood_color = "#2f855a"
        else: mood = "âš–ï¸ åˆ†åŒ–éœ‡è¡"; mood_color = "#d69e2e"

        with cols[0]:
            st.markdown(f"<div style='text-align:center; padding:5px; background:#f7fafc; border-radius:5px;'><div>ğŸ“Š å¸‚åœºæƒ…ç»ª</div><div style='font-size:18px; font-weight:bold; color:{mood_color}'>{mood}</div><div style='font-size:12px; color:#666'>æ€»æˆäº¤ {total_amount:.0f}äº¿</div></div>", unsafe_allow_html=True)
        
        for i, idx_data in enumerate(indices[:3]): # åªå±•ç¤ºå‰3ä¸ª
            color = "#c53030" if idx_data['pct'] > 0 else "#2f855a"
            bg = "#fff5f5" if idx_data['pct'] > 0 else "#f0fff4"
            with cols[i+1]:
                st.markdown(f"<div style='text-align:center; padding:5px; background:{bg}; border:1px solid {color}; border-radius:5px;'><div>{idx_data['name']}</div><div style='font-size:20px; font-weight:bold; color:{color}'>{idx_data['pct']:+.2f}%</div><div style='font-size:12px; color:#666'>{idx_data['amount']:.0f}äº¿</div></div>", unsafe_allow_html=True)
    else:
        st.caption("â³ æ­£åœ¨è¿æ¥è¡Œæƒ…æ¥å£...")

    # --- 2. æ·±åº¦æ‰«ææ§åˆ¶ ---
    with st.expander("ğŸ” æ·±åº¦æ•°æ® (æ¶¨è·Œå®¶æ•°/è¿æ¿)", expanded=False):
        c1, c2 = st.columns([1, 3])
        if c1.button("âš¡ æ‰«ææ¶¨è·Œå®¶æ•°"):
            with st.spinner("æ­£åœ¨æ•°äººå¤´ (çº¦3ç§’)..."):
                breadth = get_market_breadth_slow()
                if breadth:
                    up_ratio = int((breadth['up'] / breadth['total']) * 100)
                    st.success(f"ğŸ”´ ä¸Šæ¶¨: {breadth['up']} å®¶ | ğŸ’š ä¸‹è·Œ: {breadth['down']} å®¶ | ğŸš€ æ¶¨åœ: {breadth['limit_up']} å®¶")
                    st.progress(up_ratio, text=f"èµšé’±æ•ˆåº”: {up_ratio}%")
                else:
                    st.error("æ¥å£è¶…æ—¶")

# ================= 6. é¡µé¢å¸ƒå±€ =================

with st.sidebar:
    st.header("â˜ï¸ å“¨å…µ V9.9")
    st.caption("æé€Ÿå“åº”ç‰ˆ")
    
    with st.expander("ğŸ’¼ æŒä»“é…ç½®"):
        portfolio_input = st.text_area("æŒä»“", value=st.session_state.portfolio_text)
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            save_config(CONFIG_FILE_PORTFOLIO, portfolio_input)
            st.session_state.portfolio_text = portfolio_input
            st.toast("âœ… å·²ä¿å­˜")
    
    # æé€Ÿåˆ·æ–°æŒ‰é’®
    if st.button("ğŸ”„ æé€Ÿåˆ·æ–° (å¿«è®¯)"):
        with st.spinner("ğŸš€ åŒæ­¥ä¸­..."):
            new_data = fetch_latest_data(portfolio_input, force_fetch=False)
            save_and_merge_data(new_data)
        st.toast("âœ… åˆ·æ–°å®Œæˆ")
        time.sleep(0.3); st.rerun()
        
    st.divider()
    st.markdown("### ğŸ› ï¸ å·¥å…·ç®±")
    if st.button("âš¡ æ·±åº¦è¡¥å…¨ (æ…¢)"):
        with st.spinner("ğŸ¢ æ·±åº¦æŒ–æ˜ä¸­..."):
            new_data = fetch_latest_data(portfolio_input, force_fetch=True)
            save_and_merge_data(new_data)
        st.success("âœ… è¡¥å…¨å®Œæˆ")
        st.rerun()

# --- ä¸»é¡µé¢ ---
render_sentiment_dashboard() # ğŸ”¥ è°ƒç”¨æ–°çš„æé€Ÿä»ªè¡¨ç›˜

st.divider()
st.info(f"ğŸ“Š **æƒ…æŠ¥åº“** | å†å²åº“å­˜: {len(st.session_state.news_stream)} æ¡")

# (ä¸‹æ–¹åˆ—è¡¨æ¸²æŸ“é€»è¾‘ä¸ä¹‹å‰ä¿æŒä¸€è‡´ï¼Œä¸ºäº†ç®€æ´ï¼Œæ­¤å¤„ä»…å±•ç¤ºè°ƒç”¨)
# ... [Tabs and Render Lists Code] ...
# æ‚¨å¯ä»¥ç›´æ¥ä¿ç•™ V9.8 çš„è¿™éƒ¨åˆ†ä»£ç ï¼Œå®ƒä»¬æ˜¯é€šç”¨çš„
# å¦‚æœéœ€è¦æˆ‘æŠŠä¸‹é¢çš„å‡ ç™¾è¡Œä¹Ÿè´´å‡ºæ¥è¯·å‘Šè¯‰æˆ‘ï¼Œä½†æ ¸å¿ƒä¼˜åŒ–åœ¨ä¸ŠåŠéƒ¨åˆ†ã€‚

tabs = st.tabs(["ğŸŒŠ å…¨éƒ¨", "ğŸš¨ æŒä»“", "ğŸ¤– ç§‘æŠ€", "ğŸŒ å®è§‚", "ğŸ“œ å¤ç›˜"])

def render_simple_list(df_subset, icon=""):
    if df_subset.empty: st.caption("æš‚æ— æ•°æ®"); return
    for _, row in df_subset.iterrows():
        hl_content = highlight_text(str(row['Content']).replace("ç‚¹å‡»æŸ¥çœ‹", ""))
        link = str(row.get('Link', ''))
        # ç®€å•æ¸²æŸ“
        st.markdown(f"**{row['Time']}** {icon} {hl_content} [ğŸ”—]({link})")

with tabs[0]: render_simple_list(st.session_state.news_stream.head(50))
with tabs[1]: 
    mask = st.session_state.news_stream['Tags'].str.contains("æŒä»“", na=False)
    render_simple_list(st.session_state.news_stream[mask], "ğŸš¨")
with tabs[2]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'tech'])
with tabs[3]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'macro'])
with tabs[4]: st.caption("å¤ç›˜åŠŸèƒ½è¯·ä½¿ç”¨æ·±åº¦è¡¥å…¨æ¨¡å¼")
