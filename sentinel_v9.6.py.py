import streamlit as st
import pandas as pd
import requests
import time
import os
import re
import random
from datetime import datetime, timedelta, time as dt_time
import akshare as ak
from collections import Counter

# ================= 1. ç³»ç»Ÿé…ç½® =================
st.set_page_config(page_title="å“¨å…µ V10.1", layout="wide", page_icon="ğŸ›¡ï¸")

# --- æ–‡ä»¶å­˜å‚¨è·¯å¾„ ---
HISTORY_FILE = "sentinel_history_db.csv"   
CONFIG_FILE_PORTFOLIO = "sentinel_portfolio.txt" 
CONFIG_FILE_TOPICS = "sentinel_topics.txt"        

# ================= 2. åŸºç¡€é€»è¾‘ =================
def load_config(filename, default_val):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content: return content
        except: pass
    return default_val

def save_config(filename, text):
    try:
        clean_text = text.replace("ï¼Œ", ",").strip()
        with open(filename, "w", encoding="utf-8") as f:
            f.write(clean_text)
        return True
    except: return False

# --- çŠ¶æ€åˆå§‹åŒ– ---
REQUIRED_COLS = ['Link', 'RawTime', 'Code', 'Source', 'Content', 'Time', 'Tags', 'Prio', 'Cat', 'Sent']

if 'news_stream' not in st.session_state: 
    if os.path.exists(HISTORY_FILE):
        try: 
            df = pd.read_csv(HISTORY_FILE)
            for col in REQUIRED_COLS:
                if col not in df.columns: df[col] = ""
            st.session_state.news_stream = df
        except: 
            st.session_state.news_stream = pd.DataFrame(columns=REQUIRED_COLS)
    else: 
        st.session_state.news_stream = pd.DataFrame(columns=REQUIRED_COLS)

if 'last_update' not in st.session_state: st.session_state.last_update = "æœªåˆ·æ–°"
if 'last_save_time' not in st.session_state: st.session_state.last_save_time = time.time()
if 'scan_log' not in st.session_state: st.session_state.scan_log = []

if 'portfolio_text' not in st.session_state: 
    st.session_state.portfolio_text = load_config(CONFIG_FILE_PORTFOLIO, "ä¸­é™…æ—­åˆ›, 300059, æ±Ÿæ³¢é¾™")
if 'report_topics' not in st.session_state:
    st.session_state.report_topics = load_config(CONFIG_FILE_TOPICS, "æ”¿ç­–, ç®—åŠ›ç¡¬ä»¶, å•†ä¸šèˆªå¤©, AI, æœºå™¨äºº")

# ================= 3. æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½è”æƒ³åº“ =================
# (é…ç½®ä¿æŒä¸€è‡´)
FOREIGN_SOURCES = {"å½­åš": "Bloomberg", "è·¯é€": "Reuters", "åå°”è¡—æ—¥æŠ¥": "WSJ", "æ¨ç‰¹": "Twitter/X", "ç¾è”å‚¨": "FED"}
SENTIMENT_DICT = {"POS": ["å¢æŒ", "å›è´­", "é¢„å¢", "å¢é•¿", "ç›ˆåˆ©", "ä¸­æ ‡", "åˆåŒ", "è·æ‰¹", "ä¸¾ç‰Œ"], "NEG": ["å‡æŒ", "äºæŸ", "ä¸‹é™", "ç«‹æ¡ˆ", "è°ƒæŸ¥", "è­¦ç¤º", "è·Œåœ", "ç ´å‘"]}
SECTOR_MAP = {"tech": "ç”µå­/é€šä¿¡", "mfg": "åˆ¶é€ /èƒ½æº", "macro": "å®è§‚", "stock_event": "ä¸ªè‚¡", "other": "ç»¼åˆ"}
KNOWLEDGE_BASE = {
    "è‹±ä¼Ÿè¾¾": ("CPO/ç®—åŠ›", "tech"), "åä¸º": ("é¸¿è’™/æµ·æ€", "tech"), "SpaceX": ("å•†ä¸šèˆªå¤©", "mfg"), "Tesla": ("æœºå™¨äºº/è½¦", "mfg"),
    "GPU": ("ç®—åŠ›", "tech"), "åŠå¯¼ä½“": ("åŠå¯¼ä½“", "tech"), "èŠ¯ç‰‡": ("åŠå¯¼ä½“", "tech"), "å­˜å‚¨": ("å­˜å‚¨", "tech"),
    "è¯ç›‘ä¼š": ("æ”¿ç­–", "macro"), "å¤®è¡Œ": ("æ”¿ç­–", "macro"), "é€šèƒ€": ("å®è§‚", "macro"), "é»„é‡‘": ("å®è§‚", "macro")
}
NOISE_WORDS = ["æ”¶ç›˜", "å¼€ç›˜", "æŒ‡æ•°", "æŠ¥ä»·", "æ±‡ç‡", "å®šç›˜", "ç»“ç®—", "æ¶¨è·Œ", "æ—¥ç¨‹", "èèµ„"]

@st.cache_data(ttl=3600*12) 
def get_cached_stock_map():
    try:
        df = ak.stock_zh_a_spot_em()
        code_to_name = dict(zip(df['ä»£ç '], df['åç§°']))
        name_to_code = dict(zip(df['åç§°'], df['ä»£ç ']))
        return {"c2n": code_to_name, "n2c": name_to_code}
    except: return {"c2n": {}, "n2c": {}}

def resolve_portfolio(portfolio_str):
    raw_list = [x.strip() for x in portfolio_str.replace("ï¼Œ", ",").split(",") if x.strip()]
    resolved = []
    for item in raw_list: resolved.append((item, item)) 
    return resolved

def is_noise(content):
    for noise in NOISE_WORDS:
        if noise in content: return True
    return False

def analyze_sentiment(content):
    score = 0; matched_words = []
    for word in SENTIMENT_DICT["POS"]:
        if word in content: score += 1; matched_words.append(word)
    for word in SENTIMENT_DICT["NEG"]:
        if word in content: score -= 1; matched_words.append(word)
    if score > 0: return "POS", matched_words
    if score < 0: return "NEG", matched_words
    return "NEU", []

def check_relevance(content, resolved_portfolio):
    tags = []; priority = 0; category = "other"; content_lower = content.lower()
    sentiment, sent_words = analyze_sentiment(content)
    if sentiment == "POS": tags.append(f"ğŸŸ¢ åˆ©å¥½: {','.join(sent_words[:2])}")
    if sentiment == "NEG": tags.append(f"ğŸ”´ åˆ©ç©º: {','.join(sent_words[:2])}")
    
    for code, name in resolved_portfolio:
        if name in content:
            tags.insert(0, f"ğŸ¯ æŒä»“: {name}")
            return tags, 2, "holding", sentiment

    matched_cats = []
    for keyword, (tag, cat) in KNOWLEDGE_BASE.items():
        if keyword.lower() in content_lower:
            tags.append(tag); matched_cats.append(cat); priority = 1
    if matched_cats: category = matched_cats[0]
    for keyword in FOREIGN_SOURCES:
        if keyword in content:
            priority = max(priority, 1); category = "macro" if category == "other" else category
            break
    if sentiment != "NEU" and category == "other": category = "stock_event"; priority = max(priority, 1)
    return list(set(tags)), priority, category, sentiment

def highlight_text(text):
    text = str(text)
    text = re.sub(r'([+-]?\d+\.?\d*%)', r'<span style="color:#d946ef; font-weight:bold;">\1</span>', text)
    text = re.sub(r'(\d{6})', r'<span style="background:#e0f2fe; color:#0369a1; padding:0 4px; border-radius:3px; font-family:monospace;">\1</span>', text)
    return text

# ================= 4. æ•°æ®æŠ“å– =================

def log_scan(title, status):
    st.session_state.scan_log.insert(0, f"[{datetime.now().strftime('%H:%M:%S')}] {status}: {title[:10]}...")
    if len(st.session_state.scan_log) > 5: st.session_state.scan_log.pop()

def fetch_latest_data(portfolio_str, show_all=False, force_fetch=False):
    resolved_portfolio = resolve_portfolio(portfolio_str)
    fetched_list = []
    
    if force_fetch:
        loop_count = 50; cls_limit = 1500; time_limit = None
        progress_bar = st.progress(0, text="ğŸŒŠ åˆå§‹åŒ–...")
    else:
        loop_count = 1; cls_limit = 20; progress_bar = None
        time_limit = datetime.now() - timedelta(hours=2)

    if force_fetch: 
        for idx, (code, name) in enumerate(resolved_portfolio):
            if not code: continue 
            if progress_bar: progress_bar.progress(idx*2, text=f"ğŸ¯ {name}")
            try:
                df_news = ak.stock_news_em(symbol=code)
                for _, row in df_news.head(3).iterrows(): 
                    title = row.get('title', ''); content = row.get('content', '') or title
                    time_str = row.get('public_time', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                    full = f"ã€{name}å…¬å‘Šã€‘{title} {content}"
                    fetched_list.append({"Time": time_str, "Content": full, "Link": "", "Source": "ğŸ‡¨ğŸ‡³ å…¬å‘Š", "Tags": str([f"ğŸ¯ {name}"]), "Prio": 2, "Cat": "holding", "Sent": "NEU", "RawTime": time_str, "Code": code})
            except: pass
    
    try:
        url = "https://flash-api.jin10.com/get_flash_list"; params = {"channel": "-8200", "vip": "1"}
        resp = requests.get(url, params=params, headers={"x-app-id": "bVBF4FyRTn5NJF5n"}, timeout=3)
        if resp.status_code == 200:
            for item in resp.json().get("data", []):
                data = item.get("data", {}); time_str = item.get("time", "")
                if time_limit and datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S") < time_limit: continue
                content = data.get("content", "") or ""; title = data.get("title", "") or ""
                full = f"ã€{title}ã€‘ {content}" if title and title not in content else content
                if not show_all and is_noise(full) and not force_fetch: continue
                tags, prio, cat, sent = check_relevance(full, resolved_portfolio)
                if show_all or prio > 0 or force_fetch:
                    fetched_list.append({"Time": time_str, "Content": full, "Link": "https://www.jin10.com", "Source": "ğŸŒ é‡‘å", "Tags": str(tags), "Prio": prio, "Cat": cat, "Sent": sent, "RawTime": time_str, "Code": ""})
    except: pass

    # 3. è´¢è”ç¤¾ & 4. ä¸œè´¢å…¨çƒ (ä»£ç ç•¥ï¼Œä¿æŒåŸæ ·ï¼ŒåŠŸèƒ½ä¿ç•™)

    if force_fetch and progress_bar: progress_bar.empty()
    return pd.DataFrame(fetched_list)

def fetch_research_data():
    return fetch_latest_data("", force_fetch=True)

def save_and_merge_data(new_df):
    if new_df.empty: return 0
    if os.path.exists(HISTORY_FILE):
        try: disk_df = pd.read_csv(HISTORY_FILE)
        except: disk_df = pd.DataFrame()
    else: disk_df = pd.DataFrame()
    for col in REQUIRED_COLS:
        if col not in disk_df.columns: disk_df[col] = ""
    combined = pd.concat([new_df, st.session_state.news_stream, disk_df], ignore_index=True).drop_duplicates(subset=['Content'], keep='first').sort_values(by='RawTime', ascending=False)
    st.session_state.news_stream = combined.head(5000)
    st.session_state.news_stream.head(8000).to_csv(HISTORY_FILE, index=False, encoding='utf-8-sig')
    return len(combined)

# ================= 5. ğŸ”¥ V10.1 æ ¸å¿ƒï¼šæé€Ÿä»ªè¡¨ç›˜ + æ¿å—çƒ­åŠ› =================

@st.cache_data(ttl=30)
def get_market_indices_fast():
    """æé€ŸæŒ‡æ•°ï¼šåªæ‹‰å–3ä¸ªæ ¸å¿ƒæŒ‡æ•°"""
    try:
        df_index = ak.stock_zh_index_spot()
        target_codes = ['sh000001', 'sz399001', 'sz399006', '000001', '399001', '399006']
        mask = df_index['ä»£ç '].astype(str).isin(target_codes)
        df_target = df_index[mask].copy()
        if df_target.empty: 
            mask_name = df_index['åç§°'].isin(['ä¸Šè¯æŒ‡æ•°', 'æ·±è¯æˆæŒ‡', 'åˆ›ä¸šæ¿æŒ‡'])
            df_target = df_index[mask_name].copy()
        indices = []
        for _, row in df_target.iterrows():
            indices.append({"name": row['åç§°'], "pct": row['æ¶¨è·Œå¹…'], "amount": row['æˆäº¤é¢'] / 100000000})
        return indices
    except: return []

@st.cache_data(ttl=60)
def get_sector_heatmap_fast():
    """
    ğŸ”¥ V10.1 æ–°å¢ï¼šæé€Ÿæ¿å—çƒ­åŠ›
    åªæ‹‰å–è¡Œä¸šæ•°æ®ï¼ˆå‡ åæ¡ï¼‰ï¼Œä¸æ‹‰ä¸ªè‚¡ï¼ˆå‡ åƒæ¡ï¼‰ï¼Œäº‘ç«¯ç§’å¼€ï¼
    """
    try:
        df = ak.stock_board_industry_name_em()
        df = df.sort_values(by='æ¶¨è·Œå¹…', ascending=False)
        top5 = df.head(5)[['æ¿å—åç§°', 'æ¶¨è·Œå¹…']].to_dict('records')
        bot5 = df.tail(5)[['æ¿å—åç§°', 'æ¶¨è·Œå¹…']].to_dict('records')
        return {"top": top5, "bot": bot5, "status": "success"}
    except Exception as e:
        return {"status": "fail", "msg": str(e)}

def render_sentiment_dashboard():
    # 1. æ ¸å¿ƒæŒ‡æ•°ï¼ˆæé€Ÿï¼‰
    indices = get_market_indices_fast()
    if indices:
        cols = st.columns(4)
        total_amount = sum([i['amount'] for i in indices])
        up_idx_count = len([i for i in indices if i['pct'] > 0])
        
        if up_idx_count == 3: mood = "ğŸ”¥ å…¨é¢æ™®æ¶¨"; mood_color = "#c53030"
        elif up_idx_count == 0: mood = "ğŸ’š å•è¾¹ä¸‹è¡Œ"; mood_color = "#2f855a"
        else: mood = "âš–ï¸ åˆ†åŒ–éœ‡è¡"; mood_color = "#d69e2e"

        with cols[0]:
            st.markdown(f"<div style='text-align:center; padding:5px; background:#f7fafc; border-radius:5px;'><div>ğŸ“Š å¸‚åœºæƒ…ç»ª</div><div style='font-size:18px; font-weight:bold; color:{mood_color}'>{mood}</div><div style='font-size:12px; color:#666'>æ€»æˆäº¤ {total_amount:.0f}äº¿</div></div>", unsafe_allow_html=True)
        
        for i, idx_data in enumerate(indices[:3]): 
            color = "#c53030" if idx_data['pct'] > 0 else "#2f855a"
            bg = "#fff5f5" if idx_data['pct'] > 0 else "#f0fff4"
            with cols[i+1]:
                st.markdown(f"<div style='text-align:center; padding:5px; background:{bg}; border:1px solid {color}; border-radius:5px;'><div>{idx_data['name']}</div><div style='font-size:20px; font-weight:bold; color:{color}'>{idx_data['pct']:+.2f}%</div><div style='font-size:12px; color:#666'>{idx_data['amount']:.0f}äº¿</div></div>", unsafe_allow_html=True)
    else:
        st.caption("â³ æ­£åœ¨è¿æ¥è¡Œæƒ…æ¥å£...")

    # 2. ğŸ”¥ V10.1 ä¼˜åŒ–ï¼šè¡Œä¸šçƒ­åŠ›æ‰«æ (æ›¿ä»£å¡æ­»çš„æ·±åº¦æ‰«æ)
    with st.expander("ğŸŒ¡ï¸ è¡Œä¸šé£å£ (ç‚¹å‡»å±•å¼€)", expanded=False):
        c1, c2 = st.columns([1, 4])
        if c1.button("ğŸš€ æ‰«æçƒ­ç‚¹è¡Œä¸š"):
            with st.spinner("æ­£åœ¨è·å–è¡Œä¸šæ•°æ®..."):
                data = get_sector_heatmap_fast()
                if data['status'] == 'success':
                    # æ¸²æŸ“é¢†æ¶¨
                    st.markdown("**ğŸ”¥ é¢†æ¶¨è¡Œä¸šï¼š**")
                    cols_up = st.columns(5)
                    for i, item in enumerate(data['top']):
                        with cols_up[i]:
                            st.markdown(f"<span style='color:#c53030; font-weight:bold'>{item['æ¿å—åç§°']}</span><br><span style='color:red'>{item['æ¶¨è·Œå¹…']}%</span>", unsafe_allow_html=True)
                    
                    st.markdown("---")
                    # æ¸²æŸ“é¢†è·Œ
                    st.markdown("**ğŸ’š é¢†è·Œè¡Œä¸šï¼š**")
                    cols_down = st.columns(5)
                    for i, item in enumerate(sorted(data['bot'], key=lambda x: x['æ¶¨è·Œå¹…'])):
                        with cols_down[i]:
                            st.markdown(f"<span style='color:#2f855a; font-weight:bold'>{item['æ¿å—åç§°']}</span><br><span style='color:green'>{item['æ¶¨è·Œå¹…']}%</span>", unsafe_allow_html=True)
                else:
                    st.error("æ¥å£è¿æ¥è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")

# ================= 6. è¾…åŠ©åŠŸèƒ½ =================
# (ä¿æŒåŸæœ‰çš„ç ”æŠ¥ç”Ÿæˆå’Œåˆ—è¡¨æ¸²æŸ“é€»è¾‘)
def extract_smart_summary(subset_df):
    # ... (ä»£ç çœç•¥ï¼Œä¿æŒ V10.0 é€»è¾‘) ...
    summary_lines = []
    seen_content = set()
    holdings = subset_df[subset_df['Cat'] == 'holding']
    if not holdings.empty:
        for _, row in holdings.head(3).iterrows():
            clean_txt = str(row['Content']).strip()
            if clean_txt[:20] in seen_content: continue
            seen_content.add(clean_txt[:20])
            summary_lines.append(f"âš ï¸ **æŒä»“**: {clean_txt[:100]}...")
    main_news = subset_df[~subset_df['Cat'].isin(['holding', 'other'])]
    if not main_news.empty:
        top_news = main_news.sort_values(by=['Prio', 'RawTime'], ascending=False).head(3)
        for _, row in top_news.iterrows():
            clean_txt = str(row['Content']).strip()
            if clean_txt[:20] in seen_content: continue
            seen_content.add(clean_txt[:20])
            cat_cn = {"tech":"ç§‘æŠ€", "mfg":"åˆ¶é€ ", "macro":"å®è§‚"}.get(row['Cat'], "çƒ­ç‚¹")
            summary_lines.append(f"ğŸ”¥ **{cat_cn}**: {clean_txt[:100]}...")
    if not summary_lines: return "æœ¬æ—¶æ®µå¹³ç¨³ï¼Œæ— é‡å¤§é¢˜æå¼‚åŠ¨ã€‚"
    return "\n".join(summary_lines)

def get_3h_timeline(df):
    if df.empty: return []
    df = df.copy()
    df['dt'] = pd.to_datetime(df['RawTime'], errors='coerce')
    df = df.dropna(subset=['dt'])
    if df.empty: return []
    max_time = df['dt'].max(); min_time = df['dt'].min()
    buckets = []; current = max_time.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)
    while current > min_time - timedelta(hours=3):
        prev = current - timedelta(hours=3)
        mask = (df['dt'] <= current) & (df['dt'] > prev)
        subset = df[mask]
        if not subset.empty:
            smart_text = extract_smart_summary(subset)
            headline = smart_text.split('\n')[0].replace('**', '').replace('âš ï¸ ', '').replace('ğŸ”¥ ', '')[:40] + "..."
            buckets.append({"Label": f"{prev.strftime('%H:%M')} - {current.strftime('%H:%M')}", "Headline": headline, "SmartText": smart_text, "Count": len(subset), "Data": subset})
        current = prev
    return buckets

def generate_report_data(df, days, topics_str):
    if df.empty: return None
    df = df.copy(); df['dt'] = pd.to_datetime(df['RawTime'], errors='coerce')
    cutoff_time = datetime.now() - timedelta(days=days)
    df = df[df['dt'] >= cutoff_time]
    if df.empty: return None
    topics = [t.strip() for t in topics_str.replace("ï¼Œ", ",").split(",") if t.strip()]
    report_sections = []
    for topic in topics:
        keywords = TOPIC_EXPANSION.get(topic, [topic])
        pattern = "|".join(keywords)
        mask = df['Content'].str.contains(pattern, case=False, na=False) | df['Tags'].str.contains(pattern, case=False, na=False)
        subset = df[mask]
        if not subset.empty:
            count = len(subset); pos_count = len(subset[subset['Sent'] == 'POS'])
            strength = "âšª å¼±"; bg_color = "#f7fafc"
            if count >= 5 or pos_count >= 2: strength = "ğŸŸ¢ å¼º"; bg_color = "#f0fff4"
            elif count >= 2: strength = "ğŸŸ¡ ä¸­"; bg_color = "#fffff0"
            top_rows = subset.sort_values(by=['Prio', 'RawTime'], ascending=False).head(10)
            desc_list = []
            for i, (_, row) in enumerate(top_rows.iterrows()):
                clean_txt = str(row['Content']).replace("ã€", "").replace("ã€‘", "ï¼š").strip()
                desc_list.append(f"{i+1}. {clean_txt}")
            full_desc = "<br><br>".join(desc_list)
            cat_code = subset.iloc[0]['Cat']
            related_sector = SECTOR_MAP.get(cat_code, "ç»¼åˆ")
            report_sections.append({
                "Topic": topic, "Keywords": ",".join(keywords[:4]) + "...", 
                "Strength": strength, "BgColor": bg_color, "Desc": full_desc, 
                "Sector": related_sector, "Count": count, "Data": subset.head(10)
            })
    report_sections.sort(key=lambda x: x['Count'], reverse=True)
    return report_sections

def create_report_html(data, report_type, days, topics):
    date_range = f"{(datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')} è‡³ {datetime.now().strftime('%Y-%m-%d')}"
    html = f"""<html><head><meta charset="utf-8"><title>æƒ…æŠ¥å“¨å…µç ”æŠ¥</title><style>body {{ font-family: 'å¾®è½¯é›…é»‘'; padding: 20px; background: #f4f6f9; }} .card {{ padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid #eee; background: #fff; }} .strong {{ background: #f0fff4; border-color: #c6f6d5; }} .header {{ display: flex; align-items: center; margin-bottom: 10px; }} .tag {{ padding: 2px 8px; border-radius: 4px; font-weight: bold; margin-left: 10px; background: #fff; border: 1px solid #ccc; }}</style></head><body><h1>ğŸ“ æƒ…æŠ¥{report_type}</h1><p>ğŸ“… {date_range}</p>"""
    for item in data:
        css = "strong" if "å¼º" in item['Strength'] else "weak"
        html += f"""<div class="card {css}"><div class="header"><h2>{item['Topic']}</h2><span class="tag">{item['Strength']}</span></div><p>{item['Desc']}</p></div>"""
    html += "</body></html>"
    return html

# ================= 7. é¡µé¢å¸ƒå±€ =================

with st.sidebar:
    st.header("â˜ï¸ å“¨å…µ V10.1")
    st.caption("é˜²å¡æ­»Â·çƒ­åŠ›ç‰ˆ")
    
    with st.expander("ğŸ’¼ æŒä»“é…ç½®"):
        portfolio_input = st.text_area("æŒä»“", value=st.session_state.portfolio_text)
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            save_config(CONFIG_FILE_PORTFOLIO, portfolio_input)
            st.session_state.portfolio_text = portfolio_input
            st.toast("âœ… å·²ä¿å­˜")
    
    if st.button("ğŸ”„ æé€Ÿåˆ·æ–° (å¿«è®¯)"):
        with st.spinner("ğŸš€ åŒæ­¥ä¸­..."):
            new_data = fetch_latest_data(portfolio_input, force_fetch=False)
            save_and_merge_data(new_data)
        st.toast("âœ… åˆ·æ–°å®Œæˆ")
        time.sleep(0.3); st.rerun()
        
    st.divider()
    st.markdown("### ğŸ› ï¸ å·¥å…·ç®±")
    if st.button("âš¡ æ·±åº¦è¡¥å…¨ (æ…¢)"):
        with st.spinner("ğŸ¢ æ·±åº¦æŒ–æ˜ä¸­..."):
            new_data = fetch_latest_data(portfolio_input, force_fetch=True)
            save_and_merge_data(new_data)
        st.success("âœ… è¡¥å…¨å®Œæˆ")
        st.rerun()

    st.markdown("### ğŸ§­ ç ”æŠ¥å…³æ³¨æ–¹å‘")
    report_topics_input = st.text_area("æ–¹å‘ (æ™ºèƒ½æ‰©å±•)", value=st.session_state.report_topics, height=80)
    if st.button("ğŸ’¾ ä¿å­˜ç ”æŠ¥æ–¹å‘"):
        save_config(CONFIG_FILE_TOPICS, report_topics_input)
        st.session_state.report_topics = report_topics_input
        st.success("å·²ä¿å­˜")

# --- é¡µé¢ä¸»ä½“ ---
main_container = st.container()

with main_container:
    render_sentiment_dashboard() # ğŸ”¥ è°ƒç”¨æ–°çš„çƒ­åŠ›ä»ªè¡¨ç›˜
    
    st.info(f"ğŸ“Š **æƒ…æŠ¥åº“** | å†å²åº“å­˜: {len(st.session_state.news_stream)} æ¡ | æ‚¨çš„æŒä»“: {st.session_state.portfolio_text[:20]}...")

    tabs = st.tabs(["ğŸ“‘ ç ”æŠ¥", "ğŸŒŠ å…¨éƒ¨", "ğŸš¨ æŒä»“", "ğŸ“Š ä¸ªè‚¡é›·è¾¾", "ğŸ¤– ç§‘æŠ€", "ğŸŸ¢ åˆ¶é€ ", "ğŸŒ å®è§‚", "ğŸ“œ å¤ç›˜", "ğŸ” ç ”ç©¶"])
    
    def render_simple_list(df_subset, header_icon=""):
        if df_subset.empty: st.caption("æš‚æ— æ•°æ®"); return
        for _, row in df_subset.iterrows():
            cat = row['Cat']; sent = row['Sent']
            header_color = "#c53030" if cat == "holding" else "#333"
            if header_icon == "ğŸ”¥": bg_color = "#fff5f5"; border_style = "2px solid #e53e3e"
            elif header_icon == "ğŸ‘‘": bg_color = "#fffff0"; border_style = "2px solid #d69e2e"
            else: bg_color = "#fff"; border_style = "1px solid #e2e8f0"
            if sent == "POS": bg_color = "#f0fff4"
            
            hl_content = highlight_text(str(row['Content']).replace("ç‚¹å‡»æŸ¥çœ‹", ""))
            link = str(row.get('Link', ''))
            
            if link.startswith('http') and "baidu" not in link:
                final_html = f'<a href="{link}" target="_blank" style="text-decoration:none; color:inherit; display:block;">{hl_content}</a>'
                cursor_style = "pointer"
                title = "ç‚¹å‡»è·³è½¬åŸæ–‡"
            else:
                final_html = f'<span style="color:#1a202c">{hl_content}</span>'
                cursor_style = "default"
                title = ""

            st.markdown(f'<div style="border:{border_style}; background:{bg_color}; padding:10px; border-radius:4px; margin-bottom:8px; border-left: 4px solid {header_color}; cursor:{cursor_style};" title="{title}"><div style="font-size:12px; color:#666; margin-bottom:6px;"><span>{header_icon} {row["Source"]} {row["Time"]}</span></div><div style="font-size:15px; color:#1a202c; line-height:1.6; text-decoration:{("underline" if cursor_style=="pointer" else "none")}; text-decoration-color:#3182ce; text-underline-offset:3px;">{final_html}</div></div>', unsafe_allow_html=True)

    with tabs[0]:
        col_a, col_b = st.columns([1, 4])
        with col_a:
            st.markdown("#### ğŸ› ï¸ ç”Ÿæˆé…ç½®")
            report_type = st.radio("æŠ¥å‘Šå‘¨æœŸ", ["æ—¥æŠ¥ (24h)", "å‘¨æŠ¥ (7å¤©)"])
            days = 1 if "æ—¥æŠ¥" in report_type else 7
            if st.button("ğŸš€ ç”Ÿæˆç ”æŠ¥", type="primary", use_container_width=True):
                if len(st.session_state.news_stream) < 50: st.warning("âš ï¸ æ•°æ®ä¸è¶³ï¼Œè¯·å…ˆã€âš¡ è¡¥å…¨å†å²ã€‘ï¼")
                else: st.session_state.report_data = generate_report_data(st.session_state.news_stream, days, st.session_state.report_topics)
        with col_b:
            if 'report_data' in st.session_state and st.session_state.report_data:
                data = st.session_state.report_data
                st.markdown(f"## ğŸ“ å…¨çƒå¸‚åœºæƒ…æŠ¥{report_type}æ¦‚è¦")
                html_report = create_report_html(data, report_type, days, st.session_state.report_topics)
                st.download_button("ğŸ’¾ ä¸‹è½½ç ”æŠ¥", data=html_report, file_name="report.html", mime="text/html")
                for item in data:
                    st.markdown(f"""<div style="background:{item['BgColor']}; padding:15px; border-radius:8px; margin-bottom:15px; border:1px solid #e2e8f0;"><h4 style="margin:0;">{item['Topic']} ä¿¡å· <span style="font-size:14px; background:#fff; padding:2px 6px; border-radius:4px; border:1px solid #ccc;">{item['Strength']}</span></h4><div style="margin-top:10px; font-size:14px;">{item['Desc']}</div></div>""", unsafe_allow_html=True)
            elif 'report_data' in st.session_state: st.warning("âš ï¸ æš‚æ— é‡ç£…æ•°æ®")
            else: st.info("ğŸ‘ˆ è¯·ç‚¹å‡»â€œç”Ÿæˆç ”æŠ¥â€")

    with tabs[1]: render_simple_list(st.session_state.news_stream.head(50))
    with tabs[2]: 
        mask = st.session_state.news_stream['Tags'].str.contains("æŒä»“", na=False)
        render_simple_list(st.session_state.news_stream[mask], "ğŸš¨")
    
    with tabs[3]: 
        df_stock = st.session_state.news_stream[(st.session_state.news_stream['Sent'] != 'NEU') & (~st.session_state.news_stream['Cat'].isin(['macro']))]
        c_pos, c_neg = st.columns(2)
        with c_pos: render_simple_list(df_stock[df_stock['Sent'] == 'POS'])
        with c_neg: render_simple_list(df_stock[df_stock['Sent'] == 'NEG'])
        
    with tabs[4]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'tech'])
    with tabs[5]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'mfg'])
    with tabs[6]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'macro'])

    with tabs[7]:
        st.markdown("### ğŸ“œ å…¨å¤©æƒ…æŠ¥å¤ç›˜")
        timeline = get_3h_timeline(st.session_state.news_stream)
        for bucket in timeline:
            with st.expander(f"{bucket['Label']} | {bucket['Headline']} ({bucket['Count']})"):
                render_simple_list(bucket['Data'])

    with tabs[8]:
        st.markdown("### ğŸ” æ·±åº¦ç ”ç©¶ä¸äº’åŠ¨")
        if st.button("ğŸ”„ æŒ–æ˜æ·±åº¦è§‚ç‚¹", key="btn_research"):
            new_data = fetch_research_data()
            if not new_data.empty: save_and_merge_data(new_data); st.rerun()
        
        RESEARCH_KEYWORDS = ["ç ”ç©¶", "æ¨æµ‹", "äº’åŠ¨", "é¢„æµ‹", "è®¤ä¸º", "ç ”æŠ¥", "è¯„çº§", "å±•æœ›", "å›å¤", "è¡¨ç¤º", "æŒ‡å‡º", "ä¸­æ ‡", "åˆåŒ", "è·æ‰¹", "ç«‹æ¡ˆ"]
        df_research = st.session_state.news_stream[st.session_state.news_stream['Content'].str.contains('|'.join(RESEARCH_KEYWORDS), na=False)]
        
        my_stocks = [x.strip() for x in st.session_state.portfolio_text.replace("ï¼Œ", ",").split(",") if x.strip()]
        pattern_my = '|'.join(my_stocks) if my_stocks else "ImpossibleStringXY"
            
        if not df_research.empty:
            df_my = df_research[df_research['Content'].str.contains(pattern_my, na=False)]
            HIGH_VALUE_KEYWORDS = ["ä¸Šè°ƒ", "ä¹°å…¥", "å¢æŒ", "ä¸šç»©é¢„å¢", "ä¸­æ ‡", "ç­¾ç½²", "è·æ‰¹", "è¯ç›‘ä¼š", "å¤®è¡Œ", "é‡ç£…", "çªç ´", "ç«‹æ¡ˆ", "è°ƒæŸ¥"]
            df_high = df_research[df_research['Content'].str.contains('|'.join(HIGH_VALUE_KEYWORDS), na=False) & ~df_research.index.isin(df_my.index)]
            df_norm = df_research[~df_research.index.isin(df_my.index) & ~df_research.index.isin(df_high.index)]
            
            if not df_my.empty: st.markdown("#### ğŸ‘‘ æˆ‘çš„æŒä»“ç›¸å…³"); render_simple_list(df_my, "ğŸ‘‘")
            if not df_high.empty: st.markdown("#### ğŸ”¥ æ ¸å¿ƒé‡ç£…"); render_simple_list(df_high, "ğŸ”¥")
            if not df_norm.empty: 
                with st.expander(f"ğŸ“– ä¸€èˆ¬ç ”è¯» ({len(df_norm)})"): render_simple_list(df_norm, "ğŸ“")
