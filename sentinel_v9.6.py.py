import streamlit as st
import pandas as pd
import requests
import time
import os
import re
import random
from datetime import datetime, timedelta, time as dt_time
import akshare as ak
from collections import Counter

# ================= 1. ç³»ç»Ÿé…ç½® =================
st.set_page_config(page_title="å“¨å…µ V9.8", layout="wide", page_icon="â˜ï¸")

# --- æ–‡ä»¶å­˜å‚¨è·¯å¾„ ---
HISTORY_FILE = "sentinel_history_db.csv"   
CONFIG_FILE_PORTFOLIO = "sentinel_portfolio.txt" 
CONFIG_FILE_TOPICS = "sentinel_topics.txt"       

# ================= 2. åŸºç¡€é€»è¾‘ =================
def load_config(filename, default_val):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content: return content
        except: pass
    return default_val

def save_config(filename, text):
    try:
        clean_text = text.replace("ï¼Œ", ",").strip()
        with open(filename, "w", encoding="utf-8") as f:
            f.write(clean_text)
        return True
    except: return False

# --- ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šçŠ¶æ€åˆå§‹åŒ– (é˜²å´©æºƒ) ---
# å®šä¹‰å¿…é¡»å­˜åœ¨çš„åˆ—åï¼Œé˜²æ­¢äº‘ç«¯ç©ºå¯åŠ¨æŠ¥é”™
REQUIRED_COLS = ['Link', 'RawTime', 'Code', 'Source', 'Content', 'Time', 'Tags', 'Prio', 'Cat', 'Sent']

if 'news_stream' not in st.session_state: 
    if os.path.exists(HISTORY_FILE):
        try: 
            df = pd.read_csv(HISTORY_FILE)
            # è¡¥å…¨å¯èƒ½ç¼ºå¤±çš„åˆ—
            for col in REQUIRED_COLS:
                if col not in df.columns: df[col] = ""
            st.session_state.news_stream = df
        except: 
            # è¯»å–å¤±è´¥ï¼Œåˆ›å»ºå¸¦è¡¨å¤´çš„ç©ºè¡¨
            st.session_state.news_stream = pd.DataFrame(columns=REQUIRED_COLS)
    else: 
        # ğŸ”¥ æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆäº‘ç«¯é¦–æ¬¡è¿è¡Œï¼‰ï¼Œåˆ›å»ºå¸¦è¡¨å¤´çš„ç©ºè¡¨
        st.session_state.news_stream = pd.DataFrame(columns=REQUIRED_COLS)

if 'market_trend' not in st.session_state: st.session_state.market_trend = "åˆå§‹åŒ–..." 
if 'last_update' not in st.session_state: st.session_state.last_update = "æœªåˆ·æ–°"
if 'last_save_time' not in st.session_state: st.session_state.last_save_time = time.time()
if 'scan_log' not in st.session_state: st.session_state.scan_log = []
if 'show_dashboard' not in st.session_state: st.session_state.show_dashboard = False 

if 'portfolio_text' not in st.session_state: 
    st.session_state.portfolio_text = load_config(CONFIG_FILE_PORTFOLIO, "ä¸­é™…æ—­åˆ›, 300059, æ±Ÿæ³¢é¾™")
if 'report_topics' not in st.session_state:
    st.session_state.report_topics = load_config(CONFIG_FILE_TOPICS, "æ”¿ç­–, ç®—åŠ›ç¡¬ä»¶, å•†ä¸šèˆªå¤©, AI, æœºå™¨äºº")

# ================= 3. æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½è”æƒ³åº“ =================

FOREIGN_SOURCES = {
    "å½­åš": "Bloomberg", "è·¯é€": "Reuters", "åå°”è¡—æ—¥æŠ¥": "WSJ", "æ¨ç‰¹": "Twitter/X", "ç¾è”å‚¨": "FED"
}

SENTIMENT_DICT = {
    "POS": ["å¢æŒ", "å›è´­", "é¢„å¢", "å¢é•¿", "æ‰­äº", "ç›ˆåˆ©", "åˆ†çº¢", "ä¸­æ ‡", "åˆåŒ", "ç­¾ç½²", "è·æ‰¹", "çªç ´", "ä¸Šçº¿", "å‘å¸ƒ", "ä¸¾ç‰Œ", "ä¹°å…¥", "è·‘èµ¢", "ä¸Šè°ƒ"],
    "NEG": ["å‡æŒ", "äºæŸ", "ä¸‹é™", "é¢„å‡", "ç«‹æ¡ˆ", "è°ƒæŸ¥", "è­¦ç¤º", "é—®è¯¢", "å¤„ç½š", "è§£ç¦", "è·Œåœ", "ç ´å‘", "ä¸‹ä¿®", "åˆ©ç©º", "è¿çº¦", "è¯‰è®¼"]
}

SECTOR_MAP = {
    "tech": "ç”µå­/é€šä¿¡/åŠå¯¼ä½“", "mfg": "é«˜ç«¯åˆ¶é€ /èƒ½æº", "macro": "å®è§‚/é‡‘è", "stock_event": "ä¸ªè‚¡å¼‚åŠ¨", "other": "ç»¼åˆ"
}

BASE_POLICY = ["æ”¿ç­–", "æ„è§", "é€šçŸ¥", "è§„åˆ’", "è¡ŒåŠ¨è®¡åˆ’", "è·æ‰¹", "æ”¯æŒ", "è°£è¨€", "ç›‘ç®¡", "ç«‹æ¡ˆ", "å‘å¸ƒ", "å°å‘", "è¯ç›‘ä¼š", "å¤®è¡Œ", "è´¢æ”¿éƒ¨", "å‘æ”¹å§”", "å·¥ä¿¡éƒ¨", "å›½å¸¸ä¼š", "æ”¿æ²»å±€", "é™å‡†", "é™æ¯", "ä¸“é¡¹å€º", "é€†å›è´­", "LPR", "æˆ¿è´·", "æ–°è´¨ç”Ÿäº§åŠ›", "æ•°æ®è¦ç´ ", "ä»¥æ—§æ¢æ–°", "å›½ä¼æ”¹é©", "å¸‚å€¼ç®¡ç†", "è€å¿ƒèµ„æœ¬", "ç ”æŠ¥", "è§£è¯»", "åˆ†æ", "ç‚¹è¯„", "ç­–ç•¥", "å±•æœ›", "é¢„æµ‹", "ç ”åˆ¤", "åˆ¸å•†", "è¯åˆ¸", "è¯„çº§", "å¢æŒè¯„çº§", "ç›®æ ‡ä»·", "é¦–å¸­", "å®è§‚å›¢é˜Ÿ", "çºªè¦"]
BASE_COMPUTING = ["ç®—åŠ›", "GPU", "æœåŠ¡å™¨", "æ•°æ®ä¸­å¿ƒ", "è‹±ä¼Ÿè¾¾", "H20", "B200", "è¶…ç®—", "æ¶²å†·", "æ™ºç®—", "CPO", "å…‰æ¨¡å—", "äº¤æ¢æœº", "å…‰é€šä¿¡", "ä¸œæ•°è¥¿ç®—", "å¯’æ­¦çºª", "æµ·å…‰", "æ˜‡è…¾", "é²²é¹"]
BASE_HARDWARE = ["ç¡¬ä»¶", "æ‰‹æœº", "PC", "æ¶ˆè´¹ç”µå­", "é¢æ¿", "æ˜¾å¡", "è‹¹æœ", "åä¸º", "Mate", "ç”µå­", "AIæ‰‹æœº", "AI PC", "æŠ˜å å±", "ç©¿æˆ´è®¾å¤‡", "VR", "MR", "æ™ºèƒ½å®¶å±…"]
BASE_CHIP = ["åŠå¯¼ä½“", "èŠ¯ç‰‡", "æ™¶åœ†", "é›†æˆç”µè·¯", "IC", "ç¬¬ä¸‰ä»£", "IGBT", "MCU", "åˆ¶é€ ", "ä»£å·¥", "ä¸­èŠ¯", "å°ç§¯ç”µ", "åè™¹", "å°è£…", "æµ‹è¯•", "å°æµ‹", "é•¿ç”µ", "é€šå¯Œ", "åå¤©", "å…ˆè¿›å°è£…", "CoWoS", "å…‰åˆ»æœº", "èš€åˆ»", "è–„è†œ", "æ¸…æ´—", "è®¾å¤‡", "åŒ—æ–¹ååˆ›", "ä¸­å¾®", "ç»„ä»¶", "é›¶éƒ¨ä»¶", "ææ–™", "å…‰åˆ»èƒ¶", "é¶æ"]
BASE_STORAGE = ["å­˜å‚¨", "HBM", "DRAM", "NAND", "é—ªå­˜", "ç¾å…‰", "æµ·åŠ›å£«", "é•¿é‘«", "æ±Ÿæ³¢é¾™", "ä½°ç»´", "å…†æ˜“"]
BASE_AEROSPACE = ["å•†ä¸šèˆªå¤©", "èˆªå¤©", "ç«ç®­", "å«æ˜Ÿ", "å¤ªç©º", "å‘å°„", "æ·±ç©º", "æ˜Ÿé“¾", "SpaceX", "G60", "å£ä¿¡", "åƒå¸†", "è“ç®­", "æ˜Ÿé™…è£è€€", "ä½è½¨", "æ˜Ÿåº§", "é¥æ„Ÿ", "é€šä¿¡å«æ˜Ÿ", "æ¨è¿›", "å‘åŠ¨æœº", "æ¶²æ°§", "ç”²çƒ·", "ç‡ƒæ–™", "æ•´æµç½©", "é›¶éƒ¨ä»¶", "é«˜æ¸©åˆé‡‘", "ç¢³çº¤ç»´", "3Dæ‰“å°"]
BASE_AI = ["AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "GPT", "Sora", "ç”Ÿæˆå¼", "æœºå™¨è§†è§‰", "Agent", "OpenAI", "è±†åŒ…", "Kimi", "æ–‡å¿ƒ", "é€šä¹‰", "æ™ºè°±", "æœˆä¹‹æš—é¢", "æ–‡ç”Ÿå›¾", "æ–‡ç”Ÿè§†é¢‘", "å¤šæ¨¡æ€", "AIGC", "ç®—æ³•", "è¾¹ç¼˜è®¡ç®—"]
BASE_ROBOT = ["æœºå™¨äºº", "äººå½¢", "ä¼˜å¿…é€‰", "æ‹“æ™®", "ä¸‰èŠ±", "ç»¿çš„", "å…·èº«æ™ºèƒ½", "çµå·§æ‰‹", "ä¼ æ„Ÿå™¨", "IMU", "è§†è§‰", "å‡é€Ÿå™¨", "è°æ³¢", "RV", "ä¸æ ", "æ»šæŸ±", "è¡Œæ˜Ÿ", "ç©ºå¿ƒæ¯", "ç”µæœº", "ä¼ºæœ"]

TOPIC_EXPANSION = {
    "æ”¿ç­–": BASE_POLICY, "ç®—åŠ›": BASE_COMPUTING, "ç¡¬ä»¶": BASE_HARDWARE, "åŠå¯¼ä½“": BASE_CHIP, "èŠ¯ç‰‡": BASE_CHIP, "å­˜å‚¨": BASE_STORAGE, "å­˜å‚¨èŠ¯ç‰‡": BASE_STORAGE, "å•†ä¸šèˆªå¤©": BASE_AEROSPACE, "èˆªå¤©": BASE_AEROSPACE, "AI": BASE_AI, "æœºå™¨äºº": BASE_ROBOT,
    "ç®—åŠ›ç¡¬ä»¶": BASE_COMPUTING + BASE_HARDWARE, "å‚¨å­˜": BASE_STORAGE, "å‚¨å­˜èŠ¯ç‰‡": BASE_STORAGE, "åŠå¯¼ä½“äº§ä¸šé“¾": BASE_CHIP,
    "ä½ç©º": ["ä½ç©º", "æ— äººæœº", "eVTOL", "é£è¡Œæ±½è½¦", "é€šèˆª", "äº¿èˆª", "ä¸‡ä¸°"],
    "æ±½è½¦": ["æ±½è½¦", "æ–°èƒ½æºè½¦", "æ™ºé©¾", "è‡ªåŠ¨é©¾é©¶", "ç‰¹æ–¯æ‹‰", "é—®ç•Œ", "å°ç±³æ±½è½¦", "èµ›åŠ›æ–¯", "æ¯”äºšè¿ª"]
}

KNOWLEDGE_BASE = {
    "è‹±ä¼Ÿè¾¾": ("CPO/ç®—åŠ›", "tech"), "Nvidia": ("CPO/ç®—åŠ›", "tech"), "AMD": ("èŠ¯ç‰‡", "tech"), "å…‰æ¨¡å—": ("CPO", "tech"), "OpenAI": ("AIåº”ç”¨", "tech"), "åä¸º": ("é¸¿è’™/æµ·æ€", "tech"), "SpaceX": ("å•†ä¸šèˆªå¤©", "mfg"), "æ ¸èšå˜": ("æ ¸ç”µ", "mfg"), "ç”µåŠ›": ("ç”µç½‘", "mfg"), "Tesla": ("æœºå™¨äºº/è½¦", "mfg"), "ä½ç©º": ("ä½ç©ºç»æµ", "mfg"), "å›ºæ€": ("å›ºæ€ç”µæ± ", "mfg"), "è„‘æœº": ("è„‘æœºæ¥å£", "tech"), "äº’è”ç½‘": ("å·¥ä¸šäº’è”ç½‘", "tech"), "å¹³å°": ("å¹³å°ç»æµ", "tech"),
    "GPU": ("ç®—åŠ›", "tech"), "æœåŠ¡å™¨": ("ç®—åŠ›", "tech"), "åŠå¯¼ä½“": ("åŠå¯¼ä½“", "tech"), "èŠ¯ç‰‡": ("åŠå¯¼ä½“", "tech"), "å­˜å‚¨": ("å­˜å‚¨èŠ¯ç‰‡", "tech"), "HBM": ("å­˜å‚¨èŠ¯ç‰‡", "tech"), "å…‰åˆ»æœº": ("åŠå¯¼ä½“", "tech"), "å°æµ‹": ("åŠå¯¼ä½“", "tech"), "æ™¶åœ†": ("åŠå¯¼ä½“", "tech"), "ç«ç®­": ("å•†ä¸šèˆªå¤©", "mfg"), "å«æ˜Ÿ": ("å•†ä¸šèˆªå¤©", "mfg"), "æ˜Ÿé“¾": ("å•†ä¸šèˆªå¤©", "mfg"), "äººå½¢": ("æœºå™¨äºº", "mfg"), "å…·èº«æ™ºèƒ½": ("æœºå™¨äºº", "mfg"),
    "å…³ç¨": ("å®è§‚", "macro"), "åˆ¶è£": ("å®è§‚", "macro"), "æ±‡ç‡": ("å®è§‚", "macro"), "è¯ç›‘ä¼š": ("æ”¿ç­–", "macro"), "å¤®è¡Œ": ("æ”¿ç­–", "macro"), "ç ”æŠ¥": ("ç ”æŠ¥", "macro"), "è¯„çº§": ("ç ”æŠ¥", "macro"), "ç­–ç•¥": ("ç ”æŠ¥", "macro"),
    "é€šèƒ€": ("å®è§‚", "macro"), "CPI": ("å®è§‚", "macro"), "PPI": ("å®è§‚", "macro"), "GDP": ("å®è§‚", "macro"),
    "é»„é‡‘": ("å®è§‚", "macro"), "åŸæ²¹": ("å®è§‚", "macro"), "å¤©ç„¶æ°”": ("å®è§‚", "macro"), "æœŸè´§": ("å®è§‚", "macro"),
    "æŒ‡æ•°": ("å®è§‚", "macro"), "æˆäº¤é¢": ("å®è§‚", "macro"), "åŒ—å‘": ("å®è§‚", "macro"), "ä¸¤å¸‚": ("å®è§‚", "macro")
}

NOISE_WORDS = ["æ”¶ç›˜", "å¼€ç›˜", "æŒ‡æ•°", "æŠ¥ä»·", "æ±‡ç‡", "å®šç›˜", "ç»“ç®—", "æ¶¨è·Œ", "æ—¥ç¨‹", "å‰å€¼", "èèµ„"]

@st.cache_data(ttl=3600*12) 
def get_cached_stock_map():
    try:
        df = ak.stock_zh_a_spot_em()
        code_to_name = dict(zip(df['ä»£ç '], df['åç§°']))
        name_to_code = dict(zip(df['åç§°'], df['ä»£ç ']))
        return {"c2n": code_to_name, "n2c": name_to_code}
    except: return {"c2n": {}, "n2c": {}}

def resolve_portfolio(portfolio_str):
    raw_list = [x.strip() for x in portfolio_str.replace("ï¼Œ", ",").split(",") if x.strip()]
    resolved = []
    # æé€Ÿå¤„ç†ï¼Œä¸ä¾èµ–åºå¤§çš„å­—å…¸åŠ è½½
    for item in raw_list:
        resolved.append((item, item)) 
    return resolved

def is_noise(content):
    for noise in NOISE_WORDS:
        if noise in content: return True
    return False

def analyze_sentiment(content):
    score = 0; matched_words = []
    for word in SENTIMENT_DICT["POS"]:
        if word in content: score += 1; matched_words.append(word)
    for word in SENTIMENT_DICT["NEG"]:
        if word in content: score -= 1; matched_words.append(word)
    if score > 0: return "POS", matched_words
    if score < 0: return "NEG", matched_words
    return "NEU", []

def check_relevance(content, resolved_portfolio):
    tags = []; priority = 0; category = "other"; content_lower = content.lower()
    sentiment, sent_words = analyze_sentiment(content)
    if sentiment == "POS": tags.append(f"ğŸŸ¢ åˆ©å¥½: {','.join(sent_words[:2])}")
    if sentiment == "NEG": tags.append(f"ğŸ”´ åˆ©ç©º: {','.join(sent_words[:2])}")
    
    for code, name in resolved_portfolio:
        if name in content:
            tags.insert(0, f"ğŸ¯ æŒä»“: {name}")
            return tags, 2, "holding", sentiment

    matched_cats = []
    for keyword, (tag, cat) in KNOWLEDGE_BASE.items():
        if keyword.lower() in content_lower:
            tags.append(tag); matched_cats.append(cat); priority = 1
    if matched_cats: category = matched_cats[0]
    for keyword in FOREIGN_SOURCES:
        if keyword in content:
            if priority < 1: priority = 1
            if category == "other": category = "macro"
            break
    if sentiment != "NEU" and category == "other":
        category = "stock_event"
        if priority < 1: priority = 1
    return list(set(tags)), priority, category, sentiment

def highlight_text(text):
    text = str(text)
    text = re.sub(r'([+-]?\d+\.?\d*%)', r'<span style="color:#d946ef; font-weight:bold;">\1</span>', text)
    text = re.sub(r'(\d{6})', r'<span style="background:#e0f2fe; color:#0369a1; padding:0 4px; border-radius:3px; font-family:monospace;">\1</span>', text)
    text = re.sub(r'(\d+\.?\d*[äº¿ä¸‡])', r'<span style="color:#d97706; font-weight:bold;">\1</span>', text)
    actions = ["å¢æŒ", "ä¹°å…¥", "ä¸­æ ‡", "ç­¾ç½²", "è·æ‰¹", "ç«‹æ¡ˆ", "è°ƒæŸ¥", "çªç ´", "é¦–å‘", "å¯åŠ¨", "å‡æŒ"]
    for act in actions:
        text = text.replace(act, f'<span style="font-weight:900; color:#2d3748; background-color:#edf2f7; padding:0 2px;">{act}</span>')
    return text

# ================= 4. æ•°æ®å¤„ç† (V9.8: æé€Ÿåˆ†æµ + æ™ºèƒ½ä¼‘çœ ) =================

def log_scan(title, status):
    current_time = datetime.now().strftime("%H:%M:%S")
    st.session_state.scan_log.insert(0, f"[{current_time}] {status}: {title[:10]}...")
    if len(st.session_state.scan_log) > 5: st.session_state.scan_log.pop()

def fetch_latest_data(portfolio_str, show_all=False, force_fetch=False):
    resolved_portfolio = resolve_portfolio(portfolio_str)
    fetched_list = []
    
    if force_fetch:
        loop_count = 50; cls_limit = 1500
        progress_bar = st.progress(0, text="ğŸŒŠ æ­£åœ¨åˆå§‹åŒ– (åŠ è½½å…¨å¸‚åœºåå•)...")
        get_cached_stock_map() 
        time_limit = None
    else:
        loop_count = 1; cls_limit = 20; progress_bar = None
        time_limit = datetime.now() - timedelta(hours=2)

    # 1. æŒä»“ç‹™å‡» (ğŸ”¥ ä¸¥æ ¼é™åˆ¶ï¼šåªæœ‰ force_fetch ä¸º True æ—¶æ‰æ‰§è¡Œ)
    if force_fetch: 
        total_stocks = len(resolved_portfolio)
        for idx, (code, name) in enumerate(resolved_portfolio):
            if not code: continue 
            if progress_bar: progress_bar.progress(int((idx / (total_stocks + 1)) * 30), text=f"ğŸ¯ æ­£åœ¨ç‹™å‡»æŒä»“: {name}...")
            try:
                df_stock_news = ak.stock_news_em(symbol=code)
                for _, row in df_stock_news.head(5).iterrows(): 
                    title = row.get('title', ''); content = row.get('content', '') or title
                    time_str = row.get('public_time', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                    link = row.get('url', '') or row.get('Url', '') or row.get('link', '')
                    if not link: link = f"http://guba.eastmoney.com/list,{code}.html"
                    full = f"ã€{name}å…¬å‘Šã€‘{title} {content}"
                    fetched_list.append({
                        "Time": time_str, "Content": full, "Link": link, "Source": "ğŸ‡¨ğŸ‡³ ä¸œè´¢ä¸ªè‚¡",
                        "Tags": str([f"ğŸ¯ æŒä»“: {name}"]), "Prio": 2, "Cat": "holding", "Sent": "NEU", "RawTime": time_str, "Code": code
                    })
            except: pass
    
    # 2. é‡‘å
    max_id = ""
    for i in range(loop_count):
        if force_fetch and progress_bar: progress_bar.progress(30 + int(i), text="ğŸŒ æ‰«æé‡‘åæ•°æ®...")
        try:
            url = "https://flash-api.jin10.com/get_flash_list"
            params = {"channel": "-8200", "vip": "1", "max_time": max_id}
            headers = {"x-app-id": "bVBF4FyRTn5NJF5n", "x-version": "1.0.0"}
            resp = requests.get(url, params=params, headers=headers, timeout=3)
            if resp.status_code == 200:
                data_list = resp.json().get("data", [])
                if not data_list: break
                if data_list: max_id = data_list[-1].get("id", "")
                for item in data_list:
                    data = item.get("data", {})
                    time_str = item.get("time", "")
                    if time_limit:
                        try:
                            if datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S") < time_limit: continue
                        except: pass
                    content = data.get("content", "") or ""; title = data.get("title", "") or ""
                    item_id = item.get("id")
                    link = f"https://flash.jin10.com/detail/{item_id}" if item_id else "https://www.jin10.com"
                    full = f"ã€{title}ã€‘ {content}" if title and title not in content else content
                    if len(full) < 5: continue
                    if not show_all and is_noise(full) and not force_fetch: continue
                    tags, prio, cat, sent = check_relevance(full, resolved_portfolio)
                    if i == 0 and prio > 0 and not force_fetch: log_scan(full, "âœ…")
                    if show_all or prio > 0 or force_fetch:
                        fetched_list.append({
                            "Time": time_str, "Content": full, "Link": link, "Source": "ğŸŒ é‡‘å",
                            "Tags": str(tags), "Prio": prio, "Cat": cat, "Sent": sent, "RawTime": time_str, "Code": ""
                        })
                if force_fetch: time.sleep(0.05)
            else: break
        except: break

    # 3. è´¢è”ç¤¾
    try:
        df_cls = ak.stock_telegraph_cls(symbol="Aè‚¡24å°æ—¶ç”µæŠ¥")
        df_cls = df_cls.head(cls_limit)
        for _, row in df_cls.iterrows():
            time_str = str(row['publish_time'])
            if time_limit:
                try:
                    if datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S") < time_limit: continue
                except: pass
            content = row['content'] or ""; title = row['title'] or ""
            full = f"ã€{title}ã€‘ {content}" if title != "æ— " else content
            if not show_all and is_noise(full) and not force_fetch: continue
            tags, prio, cat, sent = check_relevance(full, resolved_portfolio)
            if not force_fetch and prio > 0: log_scan(full, "âœ…")
            if show_all or prio > 0 or force_fetch:
                fetched_list.append({
                    "Time": time_str, "Content": full, "Link": "https://www.cls.cn/telegraph", "Source": "ğŸ‡¨ğŸ‡³ è´¢è”ç¤¾",
                    "Tags": str(tags), "Prio": prio, "Cat": cat, "Sent": sent, "RawTime": time_str, "Code": ""
                })
    except: pass
    
    # 4. ä¸œè´¢å…¨çƒ
    try:
        df_em = ak.stock_info_global_em()
        limit = 100 if force_fetch else 30
        for _, row in df_em.head(limit).iterrows():
            time_str = str(row['å‘å¸ƒæ—¶é—´'])
            if time_limit:
                try:
                    if datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S") < time_limit: continue
                except: pass
            content = row['content']; title = row['æ ‡é¢˜']
            link = row['åŸæ–‡é“¾æ¥']
            if not link: link = "https://kuaixun.eastmoney.com/"
            full = f"ã€{title}ã€‘ {content}" if title else content
            if not show_all and is_noise(full) and not force_fetch: continue
            tags, prio, cat, sent = check_relevance(full, resolved_portfolio)
            if show_all or prio > 0 or force_fetch:
                fetched_list.append({
                    "Time": time_str, "Content": full, "Link": link, "Source": "ğŸš€ ä¸œè´¢",
                    "Tags": str(tags), "Prio": prio, "Cat": cat, "Sent": sent, "RawTime": time_str
                })
    except: pass

    if force_fetch and progress_bar: 
        progress_bar.progress(100, text="âœ… æŠ“å–å®Œæˆ")
        time.sleep(0.5)
        progress_bar.empty()
        
    return pd.DataFrame(fetched_list)

def fetch_research_data():
    return fetch_latest_data("", force_fetch=True)

def save_and_merge_data(new_df):
    if new_df.empty: return 0
    if os.path.exists(HISTORY_FILE):
        try: disk_df = pd.read_csv(HISTORY_FILE)
        except: disk_df = pd.DataFrame()
    else: disk_df = pd.DataFrame()
    for col in REQUIRED_COLS:
        if col not in disk_df.columns: disk_df[col] = ""
    mem_df = st.session_state.news_stream
    combined = pd.concat([new_df, mem_df, disk_df], ignore_index=True)
    combined = combined.drop_duplicates(subset=['Content'], keep='first')
    combined = combined.sort_values(by='RawTime', ascending=False)
    combined.head(8000).to_csv(HISTORY_FILE, index=False, encoding='utf-8-sig')
    st.session_state.news_stream = combined.head(5000)
    return len(combined)

@st.cache_data(ttl=60)
def get_realtime_sentiment():
    try:
        df = ak.stock_zh_a_spot_em()
        up_count = len(df[df['æ¶¨è·Œå¹…'] > 0])
        down_count = len(df[df['æ¶¨è·Œå¹…'] < 0])
        total = up_count + down_count + len(df[df['æ¶¨è·Œå¹…'] == 0])
        limit_up = len(df[df['æ¶¨è·Œå¹…'] > 9.5])
        limit_down = len(df[df['æ¶¨è·Œå¹…'] < -9.5])
        median_chg = df['æ¶¨è·Œå¹…'].median()
        total_amount = df['æˆäº¤é¢'].sum() / 100000000 
        return {
            "up": up_count, "down": down_count, "total": total,
            "limit_up": limit_up, "limit_down": limit_down,
            "median": median_chg, "amount": total_amount, "status": "success"
        }
    except Exception as e:
        return {"status": "fail", "msg": str(e)}

def render_sentiment_dashboard():
    if not st.session_state.show_dashboard:
        if st.button("ğŸŒ¡ï¸ ç‚¹å‡»åŠ è½½å®æ—¶å¤§ç›˜æƒ…ç»ª (è€—æ—¶çº¦2ç§’)", type="primary", use_container_width=True):
            st.session_state.show_dashboard = True
            st.rerun()
        return

    with st.spinner("æ­£åœ¨è¿æ¥äº¤æ˜“æ‰€è¡Œæƒ…..."):
        data = get_realtime_sentiment()
    
    if data["status"] == "fail": 
        st.warning("è¡Œæƒ…è¿æ¥å¤±è´¥ï¼Œè¯·é‡è¯•")
        return
    if data['total'] == 0: return 
    
    up_ratio = (data['up'] / data['total']) * 100
    down_ratio = (data['down'] / data['total']) * 100
    if up_ratio > 80: mood = "ğŸ”¥ æåº¦äº¢å¥‹"
    elif up_ratio > 60: mood = "ğŸ”´ å¤šå¤´ä¸»å¯¼"
    elif up_ratio < 20: mood = "â„ï¸ æåº¦å†°ç‚¹"
    elif up_ratio < 40: mood = "ğŸ’š ç©ºå¤´ä¸»å¯¼"
    else: mood = "âš–ï¸ éœ‡è¡å¹³è¡¡"
    
    html = f"""<div style="background-color:#f0f2f6; padding:15px; border-radius:10px; margin-bottom:20px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);"><div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px;"><div style="font-size:18px; font-weight:bold; color:#333;">ğŸŒ¡ï¸ å¸‚åœºå…¨æ™¯é©¾é©¶èˆ± <span style="font-size:14px; color:#666; font-weight:normal; margin-left:10px;">({mood})</span></div><div style="font-size:14px; font-weight:bold; color:#555;">æˆäº¤é¢: <span style="color:#333;">{data['amount']:.0f} äº¿</span></div></div><div style="width:100%; height:12px; background:#e2e8f0; border-radius:6px; display:flex; overflow:hidden;"><div style="width:{up_ratio}%; background:#f56565; height:100%;"></div><div style="width:{down_ratio}%; background:#48bb78; height:100%; margin-left:auto;"></div></div><div style="display:flex; justify-content:space-between; font-size:13px; margin-top:5px; color:#666;"><span style="color:#c53030; font-weight:bold;">ğŸ”´ ä¸Šæ¶¨: {data['up']} å®¶</span><span style="color:#2f855a; font-weight:bold;">ğŸ’š ä¸‹è·Œ: {data['down']} å®¶</span></div><div style="display:flex; gap:15px; margin-top:15px;"><div style="flex:1; background:#fff; padding:10px; border-radius:6px; text-align:center; border:1px solid #fee2e2;"><div style="font-size:12px; color:#999;">ğŸš€ æ¶¨åœ/è¿æ¿</div><div style="font-size:18px; color:#c53030; font-weight:bold;">{data['limit_up']}</div></div><div style="flex:1; background:#fff; padding:10px; border-radius:6px; text-align:center; border:1px solid #f0fff4;"><div style="font-size:12px; color:#999;">ğŸ“‰ è·Œåœ/æ ¸æŒ‰é’®</div><div style="font-size:18px; color:#2f855a; font-weight:bold;">{data['limit_down']}</div></div><div style="flex:1; background:#fff; padding:10px; border-radius:6px; text-align:center; border:1px solid #edf2f7;"><div style="font-size:12px; color:#999;">ğŸ“Š èµšé’±æ•ˆåº” (ä¸­ä½æ•°)</div><div style="font-size:18px; color:{'#c53030' if data['median']>0 else '#2f855a'}; font-weight:bold;">{data['median']:+.2f}%</div></div></div></div>"""
    st.markdown(html, unsafe_allow_html=True)
    if st.button("âŒ æ”¶èµ·ä»ªè¡¨ç›˜", type="secondary"):
        st.session_state.show_dashboard = False
        st.rerun()

def extract_smart_summary(subset_df):
    summary_lines = []
    seen_content = set()
    holdings = subset_df[subset_df['Cat'] == 'holding']
    if not holdings.empty:
        for _, row in holdings.head(3).iterrows():
            clean_txt = str(row['Content']).strip()
            if clean_txt[:20] in seen_content: continue
            seen_content.add(clean_txt[:20])
            summary_lines.append(f"âš ï¸ **æŒä»“**: {clean_txt[:100]}...")
    main_news = subset_df[~subset_df['Cat'].isin(['holding', 'other'])]
    if not main_news.empty:
        top_news = main_news.sort_values(by=['Prio', 'RawTime'], ascending=False).head(3)
        for _, row in top_news.iterrows():
            clean_txt = str(row['Content']).strip()
            if clean_txt[:20] in seen_content: continue
            seen_content.add(clean_txt[:20])
            cat_cn = {"tech":"ç§‘æŠ€", "mfg":"åˆ¶é€ ", "macro":"å®è§‚"}.get(row['Cat'], "çƒ­ç‚¹")
            summary_lines.append(f"ğŸ”¥ **{cat_cn}**: {clean_txt[:100]}...")
    if not summary_lines: return "æœ¬æ—¶æ®µå¹³ç¨³ï¼Œæ— é‡å¤§é¢˜æå¼‚åŠ¨ã€‚"
    return "\n".join(summary_lines)

def get_3h_timeline(df):
    if df.empty: return []
    df = df.copy()
    df['dt'] = pd.to_datetime(df['RawTime'], errors='coerce')
    df = df.dropna(subset=['dt'])
    if df.empty: return []
    max_time = df['dt'].max(); min_time = df['dt'].min()
    buckets = []; current = max_time.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)
    while current > min_time - timedelta(hours=3):
        prev = current - timedelta(hours=3)
        mask = (df['dt'] <= current) & (df['dt'] > prev)
        subset = df[mask]
        if not subset.empty:
            smart_text = extract_smart_summary(subset)
            headline = smart_text.split('\n')[0].replace('**', '').replace('âš ï¸ ', '').replace('ğŸ”¥ ', '')[:40] + "..."
            buckets.append({"Label": f"{prev.strftime('%H:%M')} - {current.strftime('%H:%M')}", "Headline": headline, "SmartText": smart_text, "Count": len(subset), "Data": subset})
        current = prev
    return buckets

def generate_report_data(df, days, topics_str):
    if df.empty: return None
    df = df.copy(); df['dt'] = pd.to_datetime(df['RawTime'], errors='coerce')
    cutoff_time = datetime.now() - timedelta(days=days)
    df = df[df['dt'] >= cutoff_time]
    if df.empty: return None
    topics = [t.strip() for t in topics_str.replace("ï¼Œ", ",").split(",") if t.strip()]
    NOISE_TITLES = ["åˆè¯„", "æ”¶ç›˜", "æ—©ç›˜", "ä¸‰å¤§æŒ‡æ•°", "æ•°æ®æ•´ç†", "è¦é—»æ±‡æ€»", "æ—¥å†", "æŠ•èµ„é¿é›·é’ˆ", "æ—©é—´æ–°é—»", "æ˜¨æ—¥", "å¤ç›˜", "ä¸€è§ˆ"]
    report_sections = []
    for topic in topics:
        keywords = TOPIC_EXPANSION.get(topic, [topic])
        pattern = "|".join(keywords)
        mask = df['Content'].str.contains(pattern, case=False, na=False) | df['Tags'].str.contains(pattern, case=False, na=False)
        if topic not in ["æ”¿ç­–", "å…¨çƒå®è§‚", "å®è§‚"]:
             mask = mask & ~df['Content'].str.contains('|'.join(NOISE_TITLES), case=False)
        subset = df[mask]
        if not subset.empty:
            count = len(subset); pos_count = len(subset[subset['Sent'] == 'POS'])
            strength = "âšª å¼±"; bg_color = "#f7fafc"
            if count >= 5 or pos_count >= 2: strength = "ğŸŸ¢ å¼º"; bg_color = "#f0fff4"
            elif count >= 2: strength = "ğŸŸ¡ ä¸­"; bg_color = "#fffff0"
            top_rows = subset.sort_values(by=['Prio', 'RawTime'], ascending=False).head(10)
            desc_list = []
            seen_content = set()
            count_valid = 0
            for i, (_, row) in enumerate(top_rows.iterrows()):
                if count_valid >= 5: break
                clean_txt = str(row['Content']).replace("ã€", "").replace("ã€‘", "ï¼š").strip()
                if clean_txt[:20] in seen_content: continue
                seen_content.add(clean_txt[:20])
                desc_list.append(f"{count_valid+1}. {clean_txt}")
                count_valid += 1
            full_desc = "<br><br>".join(desc_list)
            cat_code = subset.iloc[0]['Cat']
            related_sector = SECTOR_MAP.get(cat_code, "ç»¼åˆ")
            report_sections.append({
                "Topic": topic, "Keywords": ",".join(keywords[:4]) + "...", 
                "Strength": strength, "BgColor": bg_color, "Desc": full_desc, 
                "Sector": related_sector, "Count": count, "Data": subset.head(10)
            })
    report_sections.sort(key=lambda x: x['Count'], reverse=True)
    return report_sections

def create_report_html(data, report_type, days, topics):
    date_range = f"{(datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')} è‡³ {datetime.now().strftime('%Y-%m-%d')}"
    html = f"""
    <html>
    <head>
        <meta charset="utf-8">
        <title>æƒ…æŠ¥å“¨å…µç ”æŠ¥ {datetime.now().strftime('%Y%m%d')}</title>
        <style>
            body {{ font-family: 'å¾®è½¯é›…é»‘', sans-serif; padding: 40px; background: #f4f6f9; color: #333; }}
            .container {{ max-width: 900px; margin: 0 auto; background: #fff; padding: 40px; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); }}
            h1 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 15px; }}
            .meta {{ color: #7f8c8d; margin-bottom: 30px; font-size: 14px; }}
            .card {{ padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid #eee; }}
            .strong {{ background: #f0fff4; border-color: #c6f6d5; }}
            .medium {{ background: #fffff0; border-color: #fefcbf; }}
            .weak {{ background: #f7fafc; border-color: #edf2f7; }}
            .header {{ display: flex; align-items: center; margin-bottom: 15px; }}
            .tag {{ padding: 4px 10px; border-radius: 4px; font-weight: bold; font-size: 14px; margin-left: 10px; background: #fff; border: 1px solid #ccc; }}
            .content {{ line-height: 1.8; color: #2c3e50; font-size: 15px; }}
            .footer {{ margin-top: 40px; text-align: center; color: #aaa; font-size: 12px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ“ å…¨çƒå¸‚åœºæƒ…æŠ¥{report_type}æ¦‚è¦</h1>
            <div class="meta">ğŸ“… å‘¨æœŸ: {date_range}<br>ğŸ” è¦†ç›–æ–¹å‘: {topics}</div>
    """
    for item in data:
        css_class = "weak"
        if "å¼º" in item['Strength']: css_class = "strong"
        elif "ä¸­" in item['Strength']: css_class = "medium"
        html += f"""
        <div class="card {css_class}">
            <div class="header"><h2 style="margin:0;">{item['Topic']} ä¿¡å·</h2><span class="tag">{item['Strength']}</span></div>
            <div style="font-size:12px; color:#999; margin-bottom:10px;">æ™ºèƒ½è”æƒ³: {item['Keywords']}</div>
            <div class="content">{item['Desc']}</div>
            <div style="margin-top:15px; font-size:13px; color:#666; border-top:1px dashed #ccc; padding-top:10px;">ğŸ”— <b>äº§ä¸šé“¾å…³è”ï¼š</b>{item['Sector']}</div>
        </div>"""
    html += """<div class="footer">ç”± æƒ…æŠ¥å“¨å…µ V9.8 ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ</div></div></body></html>"""
    return html

# ================= 6. é¡µé¢å¸ƒå±€ =================

with st.sidebar:
    st.header("â˜ï¸ å“¨å…µ V9.8")
    st.caption("äº‘ç«¯/æœ¬åœ°é€šç”¨ç‰ˆ")
    
    with st.expander("ğŸ’¼ æŒä»“é…ç½®"):
        portfolio_input = st.text_area("æŒä»“", value=st.session_state.portfolio_text)
        if st.button("ğŸ’¾ ä¿å­˜"):
            save_config(CONFIG_FILE_PORTFOLIO, portfolio_input)
            st.session_state.portfolio_text = portfolio_input
            st.success("å·²ä¿å­˜")
    
    c1, c2 = st.columns(2)
    
    if c1.button("ğŸ”„ æé€Ÿåˆ·æ–°"):
        with st.spinner("ğŸš€ æé€ŸåŒæ­¥æ€»çº¿..."):
            new_data = fetch_latest_data(portfolio_input, force_fetch=False) # æé€Ÿæ¨¡å¼
            save_and_merge_data(new_data)
        st.toast("âœ… åˆ·æ–°å®Œæˆ (ç§’çº§)", icon="âš¡")
        time.sleep(0.3); st.rerun()
        
    if c2.button("âš¡ æ·±åº¦è¡¥å…¨"):
        with st.spinner("ğŸ¢ æ·±åº¦æ‰«ææŒä»“å…¬å‘Š..."):
            new_data = fetch_latest_data(portfolio_input, force_fetch=True) # æ·±åº¦æ¨¡å¼
            save_and_merge_data(new_data)
        st.success("âœ… å…¨é‡è¡¥å…¨å®Œæˆ")
        time.sleep(1); st.rerun()

    if st.button("ğŸ“¥ ç«‹å³è½ç›˜ (å­˜ç›˜)"):
        save_and_merge_data(pd.DataFrame()) 
        st.session_state.last_save_time = time.time()
        st.success(f"å·²å°† {len(st.session_state.news_stream)} æ¡æ•°æ®å†™å…¥ç¡¬ç›˜")

    st.markdown("### ğŸ§­ ç ”æŠ¥å…³æ³¨æ–¹å‘")
    report_topics_input = st.text_area("æ–¹å‘ (æ™ºèƒ½æ‰©å±•)", value=st.session_state.report_topics, height=80)
    if st.button("ğŸ’¾ ä¿å­˜ç ”æŠ¥æ–¹å‘"):
        save_config(CONFIG_FILE_TOPICS, report_topics_input)
        st.session_state.report_topics = report_topics_input
        st.success("å·²ä¿å­˜")

# --- é¡µé¢ä¸»ä½“ ---
main_container = st.container()

with main_container:
    render_sentiment_dashboard()
    
    st.info(f"ğŸ“Š **æƒ…æŠ¥åº“** | å†å²åº“å­˜: {len(st.session_state.news_stream)} æ¡ | æ‚¨çš„æŒä»“: {st.session_state.portfolio_text[:20]}...")

    tabs = st.tabs(["ğŸ“‘ ç ”æŠ¥", "ğŸŒŠ å…¨éƒ¨", "ğŸš¨ æŒä»“", "ğŸ“Š ä¸ªè‚¡é›·è¾¾", "ğŸ¤– ç§‘æŠ€", "ğŸŸ¢ åˆ¶é€ ", "ğŸŒ å®è§‚", "ğŸ“œ å¤ç›˜", "ğŸ” ç ”ç©¶"])
    
    def render_simple_list(df_subset, header_icon=""):
        for _, row in df_subset.iterrows():
            cat = row['Cat']; sent = row['Sent']
            header_color = "#c53030" if cat == "holding" else "#333"
            
            if header_icon == "ğŸ”¥": bg_color = "#fff5f5"; border_style = "2px solid #e53e3e"
            elif header_icon == "ğŸ‘‘": bg_color = "#fffff0"; border_style = "2px solid #d69e2e"
            else: bg_color = "#fff"; border_style = "1px solid #e2e8f0"
            
            if sent == "POS": bg_color = "#f0fff4"
            
            hl_content = highlight_text(str(row['Content']).replace("ç‚¹å‡»æŸ¥çœ‹", ""))
            link = str(row.get('Link', ''))
            
            if link.startswith('http') and "baidu" not in link:
                final_html = f'<a href="{link}" target="_blank" style="text-decoration:none; color:inherit; display:block;">{hl_content}</a>'
                cursor_style = "pointer"
                title = "ç‚¹å‡»è·³è½¬åŸæ–‡"
            else:
                final_html = f'<span style="color:#1a202c">{hl_content}</span>'
                cursor_style = "default"
                title = ""

            st.markdown(f'<div style="border:{border_style}; background:{bg_color}; padding:10px; border-radius:4px; margin-bottom:8px; border-left: 4px solid {header_color}; cursor:{cursor_style};" title="{title}"><div style="font-size:12px; color:#666; margin-bottom:6px;"><span>{header_icon} {row["Source"]} {row["Time"]}</span></div><div style="font-size:15px; color:#1a202c; line-height:1.6; text-decoration:{("underline" if cursor_style=="pointer" else "none")}; text-decoration-color:#3182ce; text-underline-offset:3px;">{final_html}</div></div>', unsafe_allow_html=True)

    with tabs[0]:
        col_a, col_b = st.columns([1, 4])
        with col_a:
            st.markdown("#### ğŸ› ï¸ ç”Ÿæˆé…ç½®")
            report_type = st.radio("æŠ¥å‘Šå‘¨æœŸ", ["æ—¥æŠ¥ (24h)", "å‘¨æŠ¥ (7å¤©)"])
            days = 1 if "æ—¥æŠ¥" in report_type else 7
            if st.button("ğŸš€ ç”Ÿæˆç ”æŠ¥", type="primary", use_container_width=True):
                if len(st.session_state.news_stream) < 50: st.warning("âš ï¸ æ•°æ®ä¸è¶³ï¼Œè¯·å…ˆã€âš¡ è¡¥å…¨å†å²ã€‘ï¼")
                else: st.session_state.report_data = generate_report_data(st.session_state.news_stream, days, st.session_state.report_topics)
        with col_b:
            if 'report_data' in st.session_state and st.session_state.report_data:
                data = st.session_state.report_data
                st.markdown(f"## ğŸ“ å…¨çƒå¸‚åœºæƒ…æŠ¥{report_type}æ¦‚è¦")
                html_report = create_report_html(data, report_type, days, st.session_state.report_topics)
                st.download_button("ğŸ’¾ ä¸‹è½½ç ”æŠ¥", data=html_report, file_name="report.html", mime="text/html")
                for item in data:
                    st.markdown(f"""<div style="background:{item['BgColor']}; padding:15px; border-radius:8px; margin-bottom:15px; border:1px solid #e2e8f0;"><h4 style="margin:0;">{item['Topic']} ä¿¡å· <span style="font-size:14px; background:#fff; padding:2px 6px; border-radius:4px; border:1px solid #ccc;">{item['Strength']}</span></h4><div style="margin-top:10px; font-size:14px;">{item['Desc']}</div></div>""", unsafe_allow_html=True)
            elif 'report_data' in st.session_state: st.warning("âš ï¸ æš‚æ— é‡ç£…æ•°æ®")
            else: st.info("ğŸ‘ˆ è¯·ç‚¹å‡»â€œç”Ÿæˆç ”æŠ¥â€")

    with tabs[1]: render_simple_list(st.session_state.news_stream.head(50))
    with tabs[2]: 
        mask = st.session_state.news_stream['Tags'].str.contains("æŒä»“", na=False)
        render_simple_list(st.session_state.news_stream[mask], "ğŸš¨")
    
    with tabs[3]: 
        df_stock = st.session_state.news_stream[(st.session_state.news_stream['Sent'] != 'NEU') & (~st.session_state.news_stream['Cat'].isin(['macro']))]
        c_pos, c_neg = st.columns(2)
        with c_pos: render_simple_list(df_stock[df_stock['Sent'] == 'POS'])
        with c_neg: render_simple_list(df_stock[df_stock['Sent'] == 'NEG'])
        
    with tabs[4]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'tech'])
    with tabs[5]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'mfg'])
    with tabs[6]: render_simple_list(st.session_state.news_stream[st.session_state.news_stream['Cat'] == 'macro'])

    with tabs[7]:
        st.markdown("### ğŸ“œ å…¨å¤©æƒ…æŠ¥å¤ç›˜")
        timeline = get_3h_timeline(st.session_state.news_stream)
        for bucket in timeline:
            with st.expander(f"{bucket['Label']} | {bucket['Headline']} ({bucket['Count']})"):
                render_simple_list(bucket['Data'])

    with tabs[8]:
        st.markdown("### ğŸ” æ·±åº¦ç ”ç©¶ä¸äº’åŠ¨")
        if st.button("ğŸ”„ æŒ–æ˜æ·±åº¦è§‚ç‚¹", key="btn_research"):
            new_data = fetch_research_data()
            if not new_data.empty: save_and_merge_data(new_data); st.rerun()
        
        RESEARCH_KEYWORDS = ["ç ”ç©¶", "æ¨æµ‹", "äº’åŠ¨", "é¢„æµ‹", "è®¤ä¸º", "ç ”æŠ¥", "è¯„çº§", "å±•æœ›", "å›å¤", "è¡¨ç¤º", "æŒ‡å‡º", "ä¸­æ ‡", "åˆåŒ", "è·æ‰¹", "ç«‹æ¡ˆ"]
        df_research = st.session_state.news_stream[st.session_state.news_stream['Content'].str.contains('|'.join(RESEARCH_KEYWORDS), na=False)]
        
        my_stocks = [x.strip() for x in st.session_state.portfolio_text.replace("ï¼Œ", ",").split(",") if x.strip()]
        
        # ğŸ”¥ äº‘ç«¯é€‚é…ä¼˜åŒ–ï¼šä¸ä¾èµ– stock_map ç¼“å­˜ï¼Œç›´æ¥ç”¨å­—ç¬¦ä¸²åŒ¹é…
        pattern_my = '|'.join(my_stocks) if my_stocks else "ImpossibleStringXY"
            
        if not df_research.empty:
            df_my = df_research[df_research['Content'].str.contains(pattern_my, na=False)]
            HIGH_VALUE_KEYWORDS = ["ä¸Šè°ƒ", "ä¹°å…¥", "å¢æŒ", "ä¸šç»©é¢„å¢", "ä¸­æ ‡", "ç­¾ç½²", "è·æ‰¹", "è¯ç›‘ä¼š", "å¤®è¡Œ", "é‡ç£…", "çªç ´", "ç«‹æ¡ˆ", "è°ƒæŸ¥"]
            df_high = df_research[df_research['Content'].str.contains('|'.join(HIGH_VALUE_KEYWORDS), na=False) & ~df_research.index.isin(df_my.index)]
            df_norm = df_research[~df_research.index.isin(df_my.index) & ~df_research.index.isin(df_high.index)]
            
            if not df_my.empty: st.markdown("#### ğŸ‘‘ æˆ‘çš„æŒä»“ç›¸å…³"); render_simple_list(df_my, "ğŸ‘‘")
            if not df_high.empty: st.markdown("#### ğŸ”¥ æ ¸å¿ƒé‡ç£…"); render_simple_list(df_high, "ğŸ”¥")
            if not df_norm.empty: 
                with st.expander(f"ğŸ“– ä¸€èˆ¬ç ”è¯» ({len(df_norm)})"): render_simple_list(df_norm, "ğŸ“")
